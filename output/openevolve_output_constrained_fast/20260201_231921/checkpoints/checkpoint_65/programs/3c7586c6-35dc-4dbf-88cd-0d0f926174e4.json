{"id": "3c7586c6-35dc-4dbf-88cd-0d0f926174e4", "code": "\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    # Robertson/Sparck Jones IDF (classic BM25)\n    return np.log(((N - df + 0.5) / (df + 0.5)) + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"unique\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n", "language": "python", "parent_id": "175d8f9d-bd18-4a0c-a80c-328d23828286", "generation": 6, "timestamp": 1770028953.622433, "iteration_found": 62, "metrics": {"beir_nfcorpus_ndcg@10": 0.3211914433013072, "beir_nfcorpus_recall@100": 0.2563360107955354, "beir_nfcorpus_index_time_ms": 3481.012416013982, "beir_nfcorpus_query_time_ms": 88.19845895050094, "beir_scifact_ndcg@10": 0.6795406347961755, "beir_scifact_recall@100": 0.9286666666666668, "beir_scifact_index_time_ms": 4651.411874976475, "beir_scifact_query_time_ms": 338.3259160327725, "bright_pony_ndcg@10": 0.14156506194830107, "bright_pony_recall@100": 0.34091911011262716, "bright_pony_index_time_ms": 1387.16016698163, "bright_pony_query_time_ms": 384.27154102828354, "beir_arguana_ndcg@10": 0.25197366627525464, "beir_arguana_recall@100": 0.8515346181299072, "beir_arguana_index_time_ms": 5749.826000013854, "beir_arguana_query_time_ms": 17125.58362504933, "bright_theoremqa_theorems_ndcg@10": 0.05243792872472427, "bright_theoremqa_theorems_recall@100": 0.15789473684210525, "bright_theoremqa_theorems_index_time_ms": 10461.47983398987, "bright_theoremqa_theorems_query_time_ms": 732.0048330002464, "beir_scidocs_ndcg@10": 0.14897303796689781, "beir_scidocs_recall@100": 0.34576666666666667, "beir_scidocs_index_time_ms": 18968.206292018294, "beir_scidocs_query_time_ms": 2908.4044999908656, "bright_economics_ndcg@10": 0.13752726415293298, "bright_economics_recall@100": 0.34009016703371153, "bright_economics_index_time_ms": 13528.913207992446, "bright_economics_query_time_ms": 2047.2443329636008, "bright_biology_ndcg@10": 0.1864965163785995, "bright_biology_recall@100": 0.45764791615583644, "bright_biology_index_time_ms": 14588.865416008048, "bright_biology_query_time_ms": 1961.8793340050615, "beir_fiqa_ndcg@10": 0.2396752430532132, "beir_fiqa_recall@100": 0.5371455148075518, "beir_fiqa_index_time_ms": 32437.714500003494, "beir_fiqa_query_time_ms": 5091.546958021354, "bright_earth_science_ndcg@10": 0.27582879059093, "bright_earth_science_recall@100": 0.5814375852771951, "bright_earth_science_index_time_ms": 30545.236582984217, "bright_earth_science_query_time_ms": 3446.3449169998057, "bright_stackoverflow_ndcg@10": 0.16812596887631254, "bright_stackoverflow_recall@100": 0.39812333470582734, "bright_stackoverflow_index_time_ms": 96298.48825000226, "bright_stackoverflow_query_time_ms": 6997.732124989852, "beir_trec-covid_ndcg@10": 0.650951284473309, "beir_trec-covid_recall@100": 0.10571992576869162, "beir_trec-covid_index_time_ms": 130913.48683304386, "beir_trec-covid_query_time_ms": 1256.1126250075176, "avg_ndcg@10": 0.2711905700448298, "avg_recall@100": 0.44177352108019347, "combined_score": 0.4076569308731207, "total_index_time_ms": 363011.80137402844, "total_query_time_ms": 42377.64916603919, "total_time_ms": 405389.4505400676, "datasets_evaluated": 12, "datasets_failed": 0, "error": 0.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace:\n  def idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n      \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df),...\n      return np.log((N + 1e-9) / (df + 1e-9))\nwith:\n  def idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n      \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df),...\n      # Robertson/Sparck Jones IDF (classic BM25)\n      return np.log(((N - df + 0.5) / (df + 0.5)) + 1e-9)\nChange 2: 'terms, weights = query_weights(query, self.k3, \"saturated\")' to 'terms, weights = query_weights(query, self.k3, \"unique\")'", "parent_metrics": {"beir_nfcorpus_ndcg@10": 0.32006437959136086, "beir_nfcorpus_recall@100": 0.2549442033620135, "beir_nfcorpus_index_time_ms": 3452.602541015949, "beir_nfcorpus_query_time_ms": 91.20624995557591, "beir_scifact_ndcg@10": 0.6780212636624363, "beir_scifact_recall@100": 0.9286666666666668, "beir_scifact_index_time_ms": 4676.233750011306, "beir_scifact_query_time_ms": 329.8864159733057, "bright_pony_ndcg@10": 0.07748451273448467, "bright_pony_recall@100": 0.25029186530902775, "bright_pony_index_time_ms": 1330.1659579738043, "bright_pony_query_time_ms": 409.9382500280626, "beir_arguana_ndcg@10": 0.2952142469067258, "beir_arguana_recall@100": 0.926481084939329, "beir_arguana_index_time_ms": 5637.317749962676, "beir_arguana_query_time_ms": 17383.34025000222, "bright_theoremqa_theorems_ndcg@10": 0.023780806596489876, "bright_theoremqa_theorems_recall@100": 0.1337719298245614, "bright_theoremqa_theorems_index_time_ms": 10428.311083000153, "bright_theoremqa_theorems_query_time_ms": 729.0828750119545, "beir_scidocs_ndcg@10": 0.14992968837634146, "beir_scidocs_recall@100": 0.3478333333333334, "beir_scidocs_index_time_ms": 19004.695625044405, "beir_scidocs_query_time_ms": 3002.7369579765946, "bright_economics_ndcg@10": 0.16923988487221636, "bright_economics_recall@100": 0.4016863347391702, "bright_economics_index_time_ms": 13767.364833969623, "bright_economics_query_time_ms": 2035.2801250410266, "bright_biology_ndcg@10": 0.18374451061205666, "bright_biology_recall@100": 0.43204831845608543, "bright_biology_index_time_ms": 14227.914540970232, "bright_biology_query_time_ms": 1954.2157500400208, "beir_fiqa_ndcg@10": 0.23667710486948956, "beir_fiqa_recall@100": 0.5372055285249729, "beir_fiqa_index_time_ms": 32272.27854100056, "beir_fiqa_query_time_ms": 5131.628250004724, "bright_earth_science_ndcg@10": 0.30939825600326987, "bright_earth_science_recall@100": 0.6112948089921775, "bright_earth_science_index_time_ms": 29938.34724999033, "bright_earth_science_query_time_ms": 3265.000584011432, "bright_stackoverflow_ndcg@10": 0.18447164382299205, "bright_stackoverflow_recall@100": 0.469874789493262, "bright_stackoverflow_index_time_ms": 96418.09658397688, "bright_stackoverflow_query_time_ms": 7006.455209047999, "beir_trec-covid_ndcg@10": 0.6690793014424301, "beir_trec-covid_recall@100": 0.10892541820470526, "beir_trec-covid_index_time_ms": 128791.45666700788, "beir_trec-covid_query_time_ms": 1251.591374981217, "avg_ndcg@10": 0.27475879995752445, "avg_recall@100": 0.4502520234871088, "combined_score": 0.41515337878119196, "total_index_time_ms": 359944.7851239238, "total_query_time_ms": 42590.36229207413, "total_time_ms": 402535.1474159979, "datasets_evaluated": 12, "datasets_failed": 0, "error": 0.0}, "island": 1}, "prompts": {"diff_user": {"system": "You are evolving a **constrained BM25** ranking function. We want **safe updates** only: tune hyperparameters, swap in known IDF/TF/length-norm/query-weight formulas, and combine these primitives meaningfully. Do **not** explore novel retrieval ideas \u2014 stick to BM25 and efficiently search the known space.\n\n## What you optimize\n\n- **combined_score** = 0.8 \u00d7 avg_recall@100 + 0.2 \u00d7 avg_ndcg@10 (higher is better).\n- Per-dataset: nDCG@10, Recall@100, index_time_ms, query_time_ms. Use these to target weak datasets.\n\n## What you can change (evolve)\n\n1. **Parameters** (k1, b, k3) \u2014 Tune within reasonable ranges: e.g. k1 in [0.5, 2.0], b in [0, 1], k3 in [0, 20].\n2. **idf(df, N)** \u2014 Swap for known formulas: Lucene (default), Robertson `log((N-df+0.5)/(df+0.5))`, ATIRE `log(N/df)`, BM25L `log((N+1)/(df+0.5))`, BM25+ `log((N+1)/df)`.\n3. **tf_saturated(tf, k1, norm)** \u2014 Swap for known formulas: Lucene `tf/(tf+k1*norm)` (default), Robertson `(k1+1)*tf/(tf+k1*norm)`, log-damped `log(1+tf)/(tf+k1*norm)`.\n4. **length_norm(doc_lengths, avgdl, b)** \u2014 Swap for known: pivoted `1-b+b*dl/avgdl` (default), none `1.0`, or other standard variants.\n5. **query_weights(query, k3, mode)** \u2014 Change mode or formula: \"unique\" (1 per term), \"count\" (qtf, default), \"saturated\" `(k3+1)*qtf/(k3+qtf)`.\n\nUse **SEARCH/REPLACE** diffs: SEARCH must exactly match the current code; REPLACE is your edit. Prefer **one component per edit** (e.g. only change k1/b, or only swap IDF formula).\n\n## What you must keep\n\n- **Interface**: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(query, top_k), BM25.score(query, doc_idx). Do not remove or rename these.\n- **BM25 structure**: Score = sum over query terms of (weight \u00d7 IDF \u00d7 saturated_TF). No new retrieval model.\n- **Numerical stability**: Avoid division by zero and NaNs (use a small epsilon where needed).\n\n## Guidelines\n\n- Prefer small, targeted changes (e.g. one hyperparameter or one formula swap).\n- Use known alternatives from the IR literature; do not invent new formulas.\n- This is effectively an efficient grid-search over a known search space \u2014 stay within it.\n", "user": "# Current Program Information\n- Fitness: 0.4152\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.4152\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace:\n  class Parameters:\n      k1: float = 1.1\n      b: float = 0.6\n      k3: float = 8.0\nwith:\n  class Parameters:\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\nChange 2: Replace:\n  def idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n      \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df),...\n      return np.log((N + 1.0) / (df + 0.5))\nwith:\n  def idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n      \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df),...\n      return np.log((N + 1e-9) / (df + 1e-9))\n- Metrics: beir_nfcorpus_ndcg@10: 0.3201, beir_nfcorpus_recall@100: 0.2549, beir_nfcorpus_index_time_ms: 3452.6025, beir_nfcorpus_query_time_ms: 91.2062, beir_scifact_ndcg@10: 0.6780, beir_scifact_recall@100: 0.9287, beir_scifact_index_time_ms: 4676.2338, beir_scifact_query_time_ms: 329.8864, bright_pony_ndcg@10: 0.0775, bright_pony_recall@100: 0.2503, bright_pony_index_time_ms: 1330.1660, bright_pony_query_time_ms: 409.9383, beir_arguana_ndcg@10: 0.2952, beir_arguana_recall@100: 0.9265, beir_arguana_index_time_ms: 5637.3177, beir_arguana_query_time_ms: 17383.3403, bright_theoremqa_theorems_ndcg@10: 0.0238, bright_theoremqa_theorems_recall@100: 0.1338, bright_theoremqa_theorems_index_time_ms: 10428.3111, bright_theoremqa_theorems_query_time_ms: 729.0829, beir_scidocs_ndcg@10: 0.1499, beir_scidocs_recall@100: 0.3478, beir_scidocs_index_time_ms: 19004.6956, beir_scidocs_query_time_ms: 3002.7370, bright_economics_ndcg@10: 0.1692, bright_economics_recall@100: 0.4017, bright_economics_index_time_ms: 13767.3648, bright_economics_query_time_ms: 2035.2801, bright_biology_ndcg@10: 0.1837, bright_biology_recall@100: 0.4320, bright_biology_index_time_ms: 14227.9145, bright_biology_query_time_ms: 1954.2158, beir_fiqa_ndcg@10: 0.2367, beir_fiqa_recall@100: 0.5372, beir_fiqa_index_time_ms: 32272.2785, beir_fiqa_query_time_ms: 5131.6283, bright_earth_science_ndcg@10: 0.3094, bright_earth_science_recall@100: 0.6113, bright_earth_science_index_time_ms: 29938.3472, bright_earth_science_query_time_ms: 3265.0006, bright_stackoverflow_ndcg@10: 0.1845, bright_stackoverflow_recall@100: 0.4699, bright_stackoverflow_index_time_ms: 96418.0966, bright_stackoverflow_query_time_ms: 7006.4552, beir_trec-covid_ndcg@10: 0.6691, beir_trec-covid_recall@100: 0.1089, beir_trec-covid_index_time_ms: 128791.4567, beir_trec-covid_query_time_ms: 1251.5914, avg_ndcg@10: 0.2748, avg_recall@100: 0.4503, combined_score: 0.4152, total_index_time_ms: 359944.7851, total_query_time_ms: 42590.3623, total_time_ms: 402535.1474, datasets_evaluated: 12.0000, datasets_failed: 0.0000, error: 0.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace:\n  def idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n      \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df),...\n      return np.log(1.0 + (N - df + 0.5) / (df + 0.5))\nwith:\n  def idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n      \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df),...\n      return np.log((N + 1e-9) / (df + 1e-9))\n- Metrics: beir_nfcorpus_ndcg@10: 0.3201, beir_nfcorpus_recall@100: 0.2549, beir_nfcorpus_index_time_ms: 3530.1394, beir_nfcorpus_query_time_ms: 91.2915, beir_scifact_ndcg@10: 0.6780, beir_scifact_recall@100: 0.9287, beir_scifact_index_time_ms: 4705.3291, beir_scifact_query_time_ms: 322.0968, bright_pony_ndcg@10: 0.0775, bright_pony_recall@100: 0.2503, bright_pony_index_time_ms: 1312.6000, bright_pony_query_time_ms: 409.3517, beir_arguana_ndcg@10: 0.2952, beir_arguana_recall@100: 0.9265, beir_arguana_index_time_ms: 5750.3143, beir_arguana_query_time_ms: 17377.5628, bright_theoremqa_theorems_ndcg@10: 0.0238, bright_theoremqa_theorems_recall@100: 0.1338, bright_theoremqa_theorems_index_time_ms: 10513.0994, bright_theoremqa_theorems_query_time_ms: 745.3974, beir_scidocs_ndcg@10: 0.1499, beir_scidocs_recall@100: 0.3478, beir_scidocs_index_time_ms: 19144.0276, beir_scidocs_query_time_ms: 2984.2455, bright_biology_ndcg@10: 0.1837, bright_biology_recall@100: 0.4320, bright_biology_index_time_ms: 14462.6966, bright_biology_query_time_ms: 1948.9368, bright_economics_ndcg@10: 0.1692, bright_economics_recall@100: 0.4017, bright_economics_index_time_ms: 13651.6722, bright_economics_query_time_ms: 1985.6075, beir_fiqa_ndcg@10: 0.2367, beir_fiqa_recall@100: 0.5372, beir_fiqa_index_time_ms: 32453.1184, beir_fiqa_query_time_ms: 5475.8803, bright_earth_science_ndcg@10: 0.3094, bright_earth_science_recall@100: 0.6113, bright_earth_science_index_time_ms: 31261.4822, bright_earth_science_query_time_ms: 3366.4838, bright_stackoverflow_ndcg@10: 0.1845, bright_stackoverflow_recall@100: 0.4699, bright_stackoverflow_index_time_ms: 96603.0642, bright_stackoverflow_query_time_ms: 7016.8855, beir_trec-covid_ndcg@10: 0.6691, beir_trec-covid_recall@100: 0.1089, beir_trec-covid_index_time_ms: 129549.7250, beir_trec-covid_query_time_ms: 1254.4965, avg_ndcg@10: 0.2748, avg_recall@100: 0.4503, combined_score: 0.4152, total_index_time_ms: 362937.2684, total_query_time_ms: 42978.2361, total_time_ms: 405915.5045, datasets_evaluated: 12.0000, datasets_failed: 0.0000, error: 0.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace:\n  class Parameters:\n      k1: float = 1.2\n      b: float = 0.6\n      k3: float = 8.0\nwith:\n  class Parameters:\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\nChange 2: Replace:\n  def idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n      \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df),...\n      return np.log((N - df + 0.5) / (df + 0.5) + 1e-9)\nwith:\n  def idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n      \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df),...\n      return np.log((N + 1e-9) / (df + 1e-9))\n- Metrics: beir_nfcorpus_ndcg@10: 0.3201, beir_nfcorpus_recall@100: 0.2549, beir_nfcorpus_index_time_ms: 3593.0775, beir_nfcorpus_query_time_ms: 92.1041, beir_scifact_ndcg@10: 0.6780, beir_scifact_recall@100: 0.9287, beir_scifact_index_time_ms: 4757.2126, beir_scifact_query_time_ms: 331.8781, bright_pony_ndcg@10: 0.0775, bright_pony_recall@100: 0.2503, bright_pony_index_time_ms: 1315.7097, bright_pony_query_time_ms: 409.5992, beir_arguana_ndcg@10: 0.2952, beir_arguana_recall@100: 0.9265, beir_arguana_index_time_ms: 5853.3063, beir_arguana_query_time_ms: 17479.9833, bright_theoremqa_theorems_ndcg@10: 0.0238, bright_theoremqa_theorems_recall@100: 0.1338, bright_theoremqa_theorems_index_time_ms: 10402.5826, bright_theoremqa_theorems_query_time_ms: 731.6160, beir_scidocs_ndcg@10: 0.1499, beir_scidocs_recall@100: 0.3478, beir_scidocs_index_time_ms: 19010.4276, beir_scidocs_query_time_ms: 2989.0786, bright_economics_ndcg@10: 0.1692, bright_economics_recall@100: 0.4017, bright_economics_index_time_ms: 13417.7113, bright_economics_query_time_ms: 2063.1060, bright_biology_ndcg@10: 0.1837, bright_biology_recall@100: 0.4320, bright_biology_index_time_ms: 14901.0485, bright_biology_query_time_ms: 1999.3534, beir_fiqa_ndcg@10: 0.2367, beir_fiqa_recall@100: 0.5372, beir_fiqa_index_time_ms: 32854.6724, beir_fiqa_query_time_ms: 5383.1184, bright_earth_science_ndcg@10: 0.3094, bright_earth_science_recall@100: 0.6113, bright_earth_science_index_time_ms: 29864.0003, bright_earth_science_query_time_ms: 3244.6404, bright_stackoverflow_ndcg@10: 0.1845, bright_stackoverflow_recall@100: 0.4699, bright_stackoverflow_index_time_ms: 95787.1362, bright_stackoverflow_query_time_ms: 6741.0615, beir_trec-covid_ndcg@10: 0.6691, beir_trec-covid_recall@100: 0.1089, beir_trec-covid_index_time_ms: 128176.6373, beir_trec-covid_query_time_ms: 1248.8743, avg_ndcg@10: 0.2748, avg_recall@100: 0.4503, combined_score: 0.4152, total_index_time_ms: 359933.5222, total_query_time_ms: 42714.4133, total_time_ms: 402647.9355, datasets_evaluated: 12.0000, datasets_failed: 0.0000, error: 0.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.4152)\n```python\n\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log((N + 1e-9) / (df + 1e-9))\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n\n```\nKey features: Performs well on beir_nfcorpus_ndcg@10 (0.3201), Performs well on beir_nfcorpus_recall@100 (0.2549), Performs well on beir_nfcorpus_index_time_ms (3593.0775), Performs well on beir_nfcorpus_query_time_ms (92.1041), Performs well on beir_scifact_ndcg@10 (0.6780), Performs well on beir_scifact_recall@100 (0.9287), Performs well on beir_scifact_index_time_ms (4757.2126), Performs well on beir_scifact_query_time_ms (331.8781), Performs well on bright_pony_ndcg@10 (0.0775), Performs well on bright_pony_recall@100 (0.2503), Performs well on bright_pony_index_time_ms (1315.7097), Performs well on bright_pony_query_time_ms (409.5992), Performs well on beir_arguana_ndcg@10 (0.2952), Performs well on beir_arguana_recall@100 (0.9265), Performs well on beir_arguana_index_time_ms (5853.3063), Performs well on beir_arguana_query_time_ms (17479.9833), Performs well on bright_theoremqa_theorems_ndcg@10 (0.0238), Performs well on bright_theoremqa_theorems_recall@100 (0.1338), Performs well on bright_theoremqa_theorems_index_time_ms (10402.5826), Performs well on bright_theoremqa_theorems_query_time_ms (731.6160), Performs well on beir_scidocs_ndcg@10 (0.1499), Performs well on beir_scidocs_recall@100 (0.3478), Performs well on beir_scidocs_index_time_ms (19010.4276), Performs well on beir_scidocs_query_time_ms (2989.0786), Performs well on bright_economics_ndcg@10 (0.1692), Performs well on bright_economics_recall@100 (0.4017), Performs well on bright_economics_index_time_ms (13417.7113), Performs well on bright_economics_query_time_ms (2063.1060), Performs well on bright_biology_ndcg@10 (0.1837), Performs well on bright_biology_recall@100 (0.4320), Performs well on bright_biology_index_time_ms (14901.0485), Performs well on bright_biology_query_time_ms (1999.3534), Performs well on beir_fiqa_ndcg@10 (0.2367), Performs well on beir_fiqa_recall@100 (0.5372), Performs well on beir_fiqa_index_time_ms (32854.6724), Performs well on beir_fiqa_query_time_ms (5383.1184), Performs well on bright_earth_science_ndcg@10 (0.3094), Performs well on bright_earth_science_recall@100 (0.6113), Performs well on bright_earth_science_index_time_ms (29864.0003), Performs well on bright_earth_science_query_time_ms (3244.6404), Performs well on bright_stackoverflow_ndcg@10 (0.1845), Performs well on bright_stackoverflow_recall@100 (0.4699), Performs well on bright_stackoverflow_index_time_ms (95787.1362), Performs well on bright_stackoverflow_query_time_ms (6741.0615), Performs well on beir_trec-covid_ndcg@10 (0.6691), Performs well on beir_trec-covid_recall@100 (0.1089), Performs well on beir_trec-covid_index_time_ms (128176.6373), Performs well on beir_trec-covid_query_time_ms (1248.8743), Performs well on avg_ndcg@10 (0.2748), Performs well on avg_recall@100 (0.4503), Performs well on combined_score (0.4152), Performs well on total_index_time_ms (359933.5222), Performs well on total_query_time_ms (42714.4133), Performs well on total_time_ms (402647.9355), Performs well on datasets_evaluated (12.0000), Performs well on datasets_failed (0.0000), Performs well on error (0.0000)\n\n### Program 2 (Score: 0.4152)\n```python\n\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log((N + 1e-9) / (df + 1e-9))\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n\n```\nKey features: Performs well on beir_nfcorpus_ndcg@10 (0.3201), Performs well on beir_nfcorpus_recall@100 (0.2549), Performs well on beir_nfcorpus_index_time_ms (3530.1394), Performs well on beir_nfcorpus_query_time_ms (91.2915), Performs well on beir_scifact_ndcg@10 (0.6780), Performs well on beir_scifact_recall@100 (0.9287), Performs well on beir_scifact_index_time_ms (4705.3291), Performs well on beir_scifact_query_time_ms (322.0968), Performs well on bright_pony_ndcg@10 (0.0775), Performs well on bright_pony_recall@100 (0.2503), Performs well on bright_pony_index_time_ms (1312.6000), Performs well on bright_pony_query_time_ms (409.3517), Performs well on beir_arguana_ndcg@10 (0.2952), Performs well on beir_arguana_recall@100 (0.9265), Performs well on beir_arguana_index_time_ms (5750.3143), Performs well on beir_arguana_query_time_ms (17377.5628), Performs well on bright_theoremqa_theorems_ndcg@10 (0.0238), Performs well on bright_theoremqa_theorems_recall@100 (0.1338), Performs well on bright_theoremqa_theorems_index_time_ms (10513.0994), Performs well on bright_theoremqa_theorems_query_time_ms (745.3974), Performs well on beir_scidocs_ndcg@10 (0.1499), Performs well on beir_scidocs_recall@100 (0.3478), Performs well on beir_scidocs_index_time_ms (19144.0276), Performs well on beir_scidocs_query_time_ms (2984.2455), Performs well on bright_biology_ndcg@10 (0.1837), Performs well on bright_biology_recall@100 (0.4320), Performs well on bright_biology_index_time_ms (14462.6966), Performs well on bright_biology_query_time_ms (1948.9368), Performs well on bright_economics_ndcg@10 (0.1692), Performs well on bright_economics_recall@100 (0.4017), Performs well on bright_economics_index_time_ms (13651.6722), Performs well on bright_economics_query_time_ms (1985.6075), Performs well on beir_fiqa_ndcg@10 (0.2367), Performs well on beir_fiqa_recall@100 (0.5372), Performs well on beir_fiqa_index_time_ms (32453.1184), Performs well on beir_fiqa_query_time_ms (5475.8803), Performs well on bright_earth_science_ndcg@10 (0.3094), Performs well on bright_earth_science_recall@100 (0.6113), Performs well on bright_earth_science_index_time_ms (31261.4822), Performs well on bright_earth_science_query_time_ms (3366.4838), Performs well on bright_stackoverflow_ndcg@10 (0.1845), Performs well on bright_stackoverflow_recall@100 (0.4699), Performs well on bright_stackoverflow_index_time_ms (96603.0642), Performs well on bright_stackoverflow_query_time_ms (7016.8855), Performs well on beir_trec-covid_ndcg@10 (0.6691), Performs well on beir_trec-covid_recall@100 (0.1089), Performs well on beir_trec-covid_index_time_ms (129549.7250), Performs well on beir_trec-covid_query_time_ms (1254.4965), Performs well on avg_ndcg@10 (0.2748), Performs well on avg_recall@100 (0.4503), Performs well on combined_score (0.4152), Performs well on total_index_time_ms (362937.2684), Performs well on total_query_time_ms (42978.2361), Performs well on total_time_ms (405915.5045), Performs well on datasets_evaluated (12.0000), Performs well on datasets_failed (0.0000), Performs well on error (0.0000)\n\n### Program 3 (Score: 0.4152)\n```python\n\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log((N + 1e-9) / (df + 1e-9))\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n\n```\nKey features: Performs well on beir_nfcorpus_ndcg@10 (0.3201), Performs well on beir_nfcorpus_recall@100 (0.2549), Performs well on beir_nfcorpus_index_time_ms (3452.6025), Performs well on beir_nfcorpus_query_time_ms (91.2062), Performs well on beir_scifact_ndcg@10 (0.6780), Performs well on beir_scifact_recall@100 (0.9287), Performs well on beir_scifact_index_time_ms (4676.2338), Performs well on beir_scifact_query_time_ms (329.8864), Performs well on bright_pony_ndcg@10 (0.0775), Performs well on bright_pony_recall@100 (0.2503), Performs well on bright_pony_index_time_ms (1330.1660), Performs well on bright_pony_query_time_ms (409.9383), Performs well on beir_arguana_ndcg@10 (0.2952), Performs well on beir_arguana_recall@100 (0.9265), Performs well on beir_arguana_index_time_ms (5637.3177), Performs well on beir_arguana_query_time_ms (17383.3403), Performs well on bright_theoremqa_theorems_ndcg@10 (0.0238), Performs well on bright_theoremqa_theorems_recall@100 (0.1338), Performs well on bright_theoremqa_theorems_index_time_ms (10428.3111), Performs well on bright_theoremqa_theorems_query_time_ms (729.0829), Performs well on beir_scidocs_ndcg@10 (0.1499), Performs well on beir_scidocs_recall@100 (0.3478), Performs well on beir_scidocs_index_time_ms (19004.6956), Performs well on beir_scidocs_query_time_ms (3002.7370), Performs well on bright_economics_ndcg@10 (0.1692), Performs well on bright_economics_recall@100 (0.4017), Performs well on bright_economics_index_time_ms (13767.3648), Performs well on bright_economics_query_time_ms (2035.2801), Performs well on bright_biology_ndcg@10 (0.1837), Performs well on bright_biology_recall@100 (0.4320), Performs well on bright_biology_index_time_ms (14227.9145), Performs well on bright_biology_query_time_ms (1954.2158), Performs well on beir_fiqa_ndcg@10 (0.2367), Performs well on beir_fiqa_recall@100 (0.5372), Performs well on beir_fiqa_index_time_ms (32272.2785), Performs well on beir_fiqa_query_time_ms (5131.6283), Performs well on bright_earth_science_ndcg@10 (0.3094), Performs well on bright_earth_science_recall@100 (0.6113), Performs well on bright_earth_science_index_time_ms (29938.3472), Performs well on bright_earth_science_query_time_ms (3265.0006), Performs well on bright_stackoverflow_ndcg@10 (0.1845), Performs well on bright_stackoverflow_recall@100 (0.4699), Performs well on bright_stackoverflow_index_time_ms (96418.0966), Performs well on bright_stackoverflow_query_time_ms (7006.4552), Performs well on beir_trec-covid_ndcg@10 (0.6691), Performs well on beir_trec-covid_recall@100 (0.1089), Performs well on beir_trec-covid_index_time_ms (128791.4567), Performs well on beir_trec-covid_query_time_ms (1251.5914), Performs well on avg_ndcg@10 (0.2748), Performs well on avg_recall@100 (0.4503), Performs well on combined_score (0.4152), Performs well on total_index_time_ms (359944.7851), Performs well on total_query_time_ms (42590.3623), Performs well on total_time_ms (402535.1474), Performs well on datasets_evaluated (12.0000), Performs well on datasets_failed (0.0000), Performs well on error (0.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.4151)\n```python\n\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log(1.0 + (N - df + 0.5) / (df + 0.5))\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n\n```\nKey features: Alternative approach to beir_nfcorpus_ndcg@10, Alternative approach to beir_nfcorpus_recall@100\n\n### Program D2 (Score: 0.4152)\n```python\n\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log((N + 1e-9) / (df + 1e-9))\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n\n```\nKey features: Alternative approach to beir_nfcorpus_ndcg@10, Alternative approach to beir_nfcorpus_recall@100\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.4041, Type: Experimental)\n```python\n\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 0.9\n    b: float = 0.55\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log(1.0 + (N - df + 0.5) / (df + 0.5))\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.4152, Type: Experimental)\n```python\n\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log((N + 1e-9) / (df + 1e-9))\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.3996, Type: Exploratory)\n```python\n\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 1.1\n    b: float = 0.6\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log((N + 1.0) / (df + 0.5))\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n\"\"\"\nConstrained BM25 seed \u2014 safe search over known primitives.\n\nStay within BM25: tune hyperparameters (k1, b, k3), swap IDF/TF/length-norm\nformulas for known alternatives, and combine them meaningfully. No exploration\nof novel retrieval ideas; efficient grid-search over a known search space.\n\nEvaluator contract: BM25, Corpus, tokenize, LuceneTokenizer; BM25.rank(), BM25.score().\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import LuceneTokenizer as _BaseLuceneTokenizer\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = min(int(os.environ.get(\"BM25_QUERY_WORKERS\", 32)), 32)\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# -----------------------------------------------------------------------------\n# Parameters \u2014 EVOLVE: k1, b, k3 (e.g. k1 in [0.5, 2.0], b in [0, 1])\n# -----------------------------------------------------------------------------\n\nclass Parameters:\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n\n\n# -----------------------------------------------------------------------------\n# IDF \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, ATIRE, BM25L, BM25+)\n# -----------------------------------------------------------------------------\n\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log((N + 1e-9) / (df + 1e-9))\n\n\n# -----------------------------------------------------------------------------\n# TF saturation \u2014 EVOLVE: swap for known formulas (Lucene, Robertson, log, etc.)\n# -----------------------------------------------------------------------------\n\ndef tf_saturated(tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene tf/(tf+k1*norm); Robertson (k1+1)*tf/(tf+k1*norm); log log(1+tf)/(tf+k1*norm).\"\"\"\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\ndef tf_saturated_scalar(tf: float, k1: float, norm: float) -> float:\n    return (k1 + 1.0) * tf / (tf + k1 * norm + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n# Length norm \u2014 EVOLVE: swap for known formulas (pivoted, none, log, sqrt)\n# -----------------------------------------------------------------------------\n\ndef length_norm(doc_lengths: NDArray[np.float64], avgdl: float, b: float) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Pivoted 1-b+b*dl/avgdl; none 1.0; log 1/log(e+dl); sqrt 1/sqrt(dl).\"\"\"\n    return 1.0 - b + b * (doc_lengths / max(avgdl, 1.0))\n\n\n# -----------------------------------------------------------------------------\n# Query term weights \u2014 EVOLVE: unique (1 per term), count (qtf), saturated (k3)\n# -----------------------------------------------------------------------------\n\ndef query_weights(\n    query: list[str], k3: float, mode: str = \"count\"\n) -> tuple[list[str], NDArray[np.float64]]:\n    \"\"\"EVOLVE: unique (bag-of-words), count (qtf), saturated (k3+1)*qtf/(k3+qtf). Default count matches Pyserini.\"\"\"\n    if not query:\n        return [], np.array([], dtype=np.float64)\n    cnt = Counter(query)\n    terms = list(cnt.keys())\n    if mode == \"unique\":\n        w = np.ones(len(terms), dtype=np.float64)\n    elif mode == \"count\":\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    elif mode == \"saturated\":\n        qtf = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n        w = (k3 + 1.0) * qtf / (k3 + qtf)\n    else:\n        w = np.array([float(cnt[t]) for t in terms], dtype=np.float64)\n    return terms, w\n\n\n# -----------------------------------------------------------------------------\n# Tokenization (fixed for evaluator)\n# -----------------------------------------------------------------------------\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# -----------------------------------------------------------------------------\n# Corpus (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass Corpus:\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n\n        self._vocab: dict[str, int] = {}\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = len(self._vocab)\n        V = len(self._vocab)\n\n        tf_lil = lil_matrix((V, self.N), dtype=np.float64)\n        self._posting_lists: dict[int, list[int]] = {i: [] for i in range(V)}\n        self._df = np.zeros(V, dtype=np.float64)\n\n        for doc_idx, doc in enumerate(documents):\n            seen = set()\n            for term, count in Counter(doc).items():\n                tid = self._vocab[term]\n                tf_lil[tid, doc_idx] = count\n                if tid not in seen:\n                    self._posting_lists[tid].append(doc_idx)\n                    self._df[tid] += 1\n                    seen.add(tid)\n\n        self.tf_matrix = csr_matrix(tf_lil)\n        self._posting_lists = {\n            tid: np.array(doc_ids, dtype=np.int64)\n            for tid, doc_ids in self._posting_lists.items()\n            if doc_ids\n        }\n\n    def __len__(self) -> int:\n        return self.N\n\n    def get_df(self, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self._df[tid]) if tid is not None else 0\n\n    def get_df_by_id(self, term_id: int) -> int:\n        return int(self._df[term_id])\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        tid = self._vocab.get(term)\n        return int(self.tf_matrix[tid, doc_idx]) if tid is not None else 0\n\n    def get_tf_by_id(self, term_id: int, doc_idx: int) -> float:\n        return float(self.tf_matrix[term_id, doc_idx])\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        tid = self._vocab.get(term)\n        return self._posting_lists.get(tid, np.array([], dtype=np.int64)) if tid is not None else np.array([], dtype=np.int64)\n\n    def get_posting_list_by_id(self, term_id: int) -> NDArray[np.int64]:\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[i] for i in ids if i in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self._vocab)\n\n    @property\n    def idf_array(self) -> NDArray[np.float64]:\n        return idf(self._df, self.N)\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n\n# -----------------------------------------------------------------------------\n# BM25 (interface fixed for evaluator)\n# -----------------------------------------------------------------------------\n\nclass BM25:\n    def __init__(\n        self,\n        corpus: Corpus,\n        k1: float | None = None,\n        b: float | None = None,\n        k3: float | None = None,\n    ):\n        self.corpus = corpus\n        self.k1 = k1 if k1 is not None else Parameters.k1\n        self.b = b if b is not None else Parameters.b\n        self.k3 = k3 if k3 is not None else Parameters.k3\n        self.idf_array = idf(corpus._df, corpus.N)\n        self.norm_array = length_norm(corpus.doc_lengths, corpus.avgdl, self.b)\n        self._idf_by_term = {term: float(self.idf_array[tid]) for term, tid in corpus._vocab.items()}\n\n    def score_document(self, query_terms: list[str], doc_idx: int) -> float:\n        \"\"\"EVOLVE: same formula as vectorized path (IDF \u00d7 saturated TF, sum).\"\"\"\n        norm = self.norm_array[doc_idx]\n        s = 0.0\n        for term in query_terms:\n            idf_val = self._idf_by_term.get(term, 0.0)\n            if idf_val == 0:\n                continue\n            tf_val = self.corpus.get_tf(doc_idx, term)\n            if tf_val == 0:\n                continue\n            s += idf_val * tf_saturated_scalar(float(tf_val), self.k1, norm)\n        return s\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n        norms = self.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        for i, tid in enumerate(query_term_ids):\n            idf_val = self.idf_array[tid]\n            if idf_val <= 0:\n                continue\n            w = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[tid, candidate_docs].toarray().flatten()\n            scores += w * idf_val * tf_saturated(tf_row, self.k1, norms)\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[NDArray[np.int64], NDArray[np.float64]]:\n        if not query:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n        term_ids = []\n        w_arr = []\n        for t, w in zip(terms, weights):\n            tid = self.corpus.get_term_id(t)\n            if tid is not None:\n                term_ids.append(tid)\n                w_arr.append(w)\n        if not term_ids:\n            return np.arange(self.corpus.N, dtype=np.int64), np.zeros(self.corpus.N, dtype=np.float64)\n        w_arr = np.array(w_arr, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for tid in term_ids:\n            candidate_set.update(self.corpus.get_posting_list_by_id(tid).tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        cand_scores = self._score_candidates_vectorized(term_ids, candidate_docs, w_arr)\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = cand_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices, sorted_scores = sorted_indices[:top_k], sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[NDArray[np.int64], NDArray[np.float64]]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(q, top_k) for q in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as ex:\n            return list(ex.map(lambda q: self.rank(q, top_k), queries))\n\n    def score(self, query: list[str], doc_idx: int) -> float:\n        return self.score_document(query, doc_idx)\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"Parameters\",\n    \"idf\",\n    \"tf_saturated\",\n    \"length_norm\",\n    \"query_weights\",\n]\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Two safe, targeted knobs to try next (both within standard BM25 variants):\n\n1) **Switch IDF to Robertson**: Your current IDF is essentially ATIRE `log(N/df)` (with eps). Robertson/Sparck Jones IDF often improves ranking quality (esp. nDCG) by tempering extremely-rare terms and handling frequent terms more gracefully.\n\n2) **Use \u201cunique\u201d query term weighting**: Many BEIR-style queries are short and repetition is usually not semantically meaningful; saturating qtf with k3 can sometimes over-emphasize repeated tokens (or tokenizer artifacts). Using unique weights is a common stable choice and can help nDCG@10 without harming recall too much.\n\n### Change 1: IDF \u2192 Robertson\n<<<<<<< SEARCH\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    return np.log((N + 1e-9) / (df + 1e-9))\n=======\ndef idf(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n    \"\"\"EVOLVE: Lucene default; alternatives: Robertson log((N-df+0.5)/(df+0.5)), ATIRE log(N/df), BM25L log((N+1)/(df+0.5)), BM25+ log((N+1)/df).\"\"\"\n    # Robertson/Sparck Jones IDF (classic BM25)\n    return np.log(((N - df + 0.5) / (df + 0.5)) + 1e-9)\n>>>>>>> REPLACE\n\n### Change 2: Query weights mode \u2192 \"unique\" (instead of \"saturated\")\nThis keeps the BM25 structure intact (weight \u00d7 IDF \u00d7 saturated TF), just changes the query-term weight primitive.\n<<<<<<< SEARCH\n        terms, weights = query_weights(query, self.k3, \"saturated\")\n=======\n        terms, weights = query_weights(query, self.k3, \"unique\")\n>>>>>>> REPLACE"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}