{"id": "954bbc29-5e9b-4838-8b05-e0bc785460dd", "code": "\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n    alpha: float = 1.0\n    beta: float = 1.0\n\n    # Light document-level priors\n    gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    # Burstiness-aware TF compression, but now made *rarity-adaptive* (protects recall for rare terms)\n    tf_log_mix: float = 0.35  # base strength (still used, but gated by rarity)\n    tf_log_k: float = 1.0     # higher => weaker log compression\n    tf_mix_idf_pivot: float = 2.2   # lucene-idf pivot: above this => little/no log compression\n    tf_mix_idf_sharp: float = 1.0   # larger => sharper transition around pivot\n\n    # Restore helpful TF blend for long/noisy docs\n    tf_salience_alpha: float = 0.35  # 0 => ignore salience; 1 => only salience\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def tf_salience(tf: float, dl: float, avgdl: float) -> float:\n        \"\"\"\n        Length-aware TF salience: downweights inflated TF in long docs.\n        Works as a smooth alternative evidence channel to protect recall.\n        \"\"\"\n        denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n        return tf / (denom + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def tf_salience_vectorized(\n        tf: NDArray[np.float64], dl: NDArray[np.float64], avgdl: float\n    ) -> NDArray[np.float64]:\n        denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n        return tf / (denom + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_logtf_lucene(tf: float, k1: float, norm: float, k: float) -> float:\n        \"\"\"\n        New primitive: log-compressed TF then Lucene saturation.\n        This reduces dominance of bursty terms (common in long docs / code dumps)\n        while keeping tf=1 close to standard behavior.\n        \"\"\"\n        if tf <= 0:\n            return 0.0\n        kk = max(k, EvolvedParameters.epsilon)\n        t = math.log1p(tf / kk)\n        denom = t + k1 * norm + EvolvedParameters.epsilon\n        return t / denom\n\n    @staticmethod\n    def saturate_logtf_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64], k: float\n    ) -> NDArray[np.float64]:\n        kk = float(max(k, EvolvedParameters.epsilon))\n        t = np.log1p(tf / kk)\n        denom = t + k1 * norm + EvolvedParameters.epsilon\n        return t / denom\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded rarity for coordination/priors: log1p((1-p)/p) where p=df/N.\n        Helps avoid ultra-rare terms fully dominating rarity-mass coverage.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        # 1 + strength * pivot/(pivot+idf)\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float\n    ) -> float:\n        \"\"\"\n        New primitive: coordination based on rarity-mass coverage instead of term-count coverage.\n        Intuition: matching rare query terms should matter more than matching generic ones.\n        Returns (matched_rarity/total_rarity)^beta with smoothing.\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        m = max(0.0, matched_rarity)\n        return (m / t) ** max(0.0, beta)\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        return coverage * coverage\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n\n        # Rarity-adaptive burstiness handling:\n        # - rare terms (high idf): keep mostly standard saturation (protect recall)\n        # - common terms (low idf): allow more log-TF compression (reduce noisy bursts)\n        base_mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n        pivot = float(EvolvedParameters.tf_mix_idf_pivot)\n        sharp = float(max(EvolvedParameters.epsilon, EvolvedParameters.tf_mix_idf_sharp))\n        gate = 1.0 / (1.0 + math.exp((idf - pivot) / sharp))  # high for common terms\n        mix = base_mix * gate\n\n        tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n        tf_logsat = ScoringPrimitives.saturate_logtf_lucene(tf, k1, norm, EvolvedParameters.tf_log_k)\n        tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n\n        # Add a second evidence channel that is robust for long docs.\n        a = float(max(0.0, min(1.0, float(EvolvedParameters.tf_salience_alpha))))\n        tf_sal = ScoringPrimitives.tf_salience(tf, dl, avgdl)\n        tf_comp = (1.0 - a) * tf_comp + a * tf_sal\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong.\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # New: rarity-aware coordination multiplier improves early precision (nDCG@10)\n        # while being less harsh than count-based coordination on long/noisy queries.\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity, total_rarity, EvolvedParameters.coord_beta\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        # Deduplicate terms and use saturated qtf weighting (classic BM25 query term factor idea)\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    return DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        dls = self.corpus.doc_lengths[candidate_docs]\n        avgdl = self.corpus.avgdl\n\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        base_mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n        pivot = float(EvolvedParameters.tf_mix_idf_pivot)\n        sharp = float(max(EvolvedParameters.epsilon, EvolvedParameters.tf_mix_idf_sharp))\n        sal_a = float(max(0.0, min(1.0, float(EvolvedParameters.tf_salience_alpha))))\n\n        for i, term_id in enumerate(query_term_ids):\n            idf = float(self.corpus.idf_array[term_id])\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            present = (tf_row > 0).astype(np.float64)\n            matched += present\n\n            # Rarity-adaptive mix (same logic as TermScorer, vectorized)\n            gate = 1.0 / (1.0 + math.exp((idf - pivot) / sharp))\n            mix = base_mix * gate\n\n            tf_sat = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            tf_logsat = ScoringPrimitives.saturate_logtf_lucene_vectorized(\n                tf_row, k1, norms, EvolvedParameters.tf_log_k\n            )\n            tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n\n            if sal_a > 0:\n                tf_sal = ScoringPrimitives.tf_salience_vectorized(tf_row, dls, avgdl)\n                tf_comp = (1.0 - sal_a) * tf_comp + sal_a * tf_sal\n\n            scores += weight * idf * rescue * tf_comp\n\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n        if EvolvedParameters.coord_beta > 0 and qn > 0:\n            # balanced rarity per query term (bounded)\n            df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n            rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n            rarity_q = np.maximum(rarity_q, 0.0)\n            total_rarity = float(np.sum(rarity_q))\n            if total_rarity > 0:\n                # matched_rarity: sum rarity of query terms present in doc\n                matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                for i, term_id in enumerate(query_term_ids):\n                    tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                    matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n\n                scores *= np.power(\n                    np.maximum(matched_rarity / total_rarity, 0.0),\n                    EvolvedParameters.coord_beta,\n                )\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        # Keep rank() consistent with QueryProcessor: dedup + saturated qtf\n        term_counts = Counter(query)\n        query_term_ids: list[int] = []\n        query_term_weights: list[float] = []\n        for term, count in term_counts.items():\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(\n                    ScoringPrimitives.query_weight_saturated(float(count), EvolvedParameters.k3)\n                )\n\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n", "language": "python", "parent_id": "9f6aa38d-8ab6-4f9c-b4d3-328145db60dd", "generation": 5, "timestamp": 1770043454.277966, "iteration_found": 54, "metrics": {"beir_nfcorpus_ndcg@10": 0.31400363001809295, "beir_nfcorpus_recall@100": 0.2545587088870478, "beir_nfcorpus_index_time_ms": 3538.0107919918373, "beir_nfcorpus_query_time_ms": 151.01504197809845, "beir_scifact_ndcg@10": 0.6758591186066004, "beir_scifact_recall@100": 0.9246666666666666, "beir_scifact_index_time_ms": 4744.103125005495, "beir_scifact_query_time_ms": 592.5310419988818, "bright_pony_ndcg@10": 0.13135060577666127, "bright_pony_recall@100": 0.3315342984087365, "bright_pony_index_time_ms": 1363.890583976172, "bright_pony_query_time_ms": 842.1074579819106, "beir_arguana_ndcg@10": 0.26068471943666705, "beir_arguana_recall@100": 0.8822269807280514, "beir_arguana_index_time_ms": 5761.212958022952, "beir_arguana_query_time_ms": 38873.91100003151, "bright_theoremqa_theorems_ndcg@10": 0.035470697599433915, "bright_theoremqa_theorems_recall@100": 0.14035087719298245, "bright_theoremqa_theorems_index_time_ms": 10449.715750000905, "bright_theoremqa_theorems_query_time_ms": 1560.5345420190133, "beir_scidocs_ndcg@10": 0.14403767567950834, "beir_scidocs_recall@100": 0.33858333333333335, "beir_scidocs_index_time_ms": 19362.38104198128, "beir_scidocs_query_time_ms": 4967.66787499655, "bright_economics_ndcg@10": 0.1358185610007905, "bright_economics_recall@100": 0.36097119634473906, "bright_economics_index_time_ms": 13982.274874986615, "bright_economics_query_time_ms": 4418.312458961736, "bright_biology_ndcg@10": 0.2657611497530769, "bright_biology_recall@100": 0.5386773505833291, "bright_biology_index_time_ms": 14939.72579203546, "bright_biology_query_time_ms": 4142.738084017765, "beir_fiqa_ndcg@10": 0.2227788386517872, "beir_fiqa_recall@100": 0.5226466905865054, "beir_fiqa_index_time_ms": 32592.083249997813, "beir_fiqa_query_time_ms": 8868.147749977652, "bright_earth_science_ndcg@10": 0.3380038700445544, "bright_earth_science_recall@100": 0.6503841320254661, "bright_earth_science_index_time_ms": 29920.03391601611, "bright_earth_science_query_time_ms": 6898.78329198109, "bright_stackoverflow_ndcg@10": 0.17490052226966335, "bright_stackoverflow_recall@100": 0.4413300343948346, "bright_stackoverflow_index_time_ms": 96701.49750000564, "bright_stackoverflow_query_time_ms": 15719.542959006503, "beir_trec-covid_ndcg@10": 0.6307937740714845, "beir_trec-covid_recall@100": 0.10231240845777469, "beir_trec-covid_index_time_ms": 129657.16724999947, "beir_trec-covid_query_time_ms": 2008.8028340251185, "avg_ndcg@10": 0.2774552635756934, "avg_recall@100": 0.45735355646745557, "combined_score": 0.4213738978891032, "total_index_time_ms": 363012.09683401976, "total_query_time_ms": 89044.09433697583, "total_time_ms": 452056.1911709956, "datasets_evaluated": 12, "datasets_failed": 0, "error": 0.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace:\n  class EvolvedParameters:\n      \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\n      delta: float = 0.5\n      alpha: float = 1.0\n      beta: float = 1.0\n  \n      # Light document-level priors\n      gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n  \n      # Frequent-term recall rescue (bounded)\n      common_strength: float = 0.25\n      common_pivot: float = 2.5\n  \n      # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n      coord_beta: float = 0.55\n  \n      # New: burstiness-aware TF compression (helps noisy/repetitive docs; preserves 1-hit signal)\n      tf_log_mix: float = 0.35  # 0 => pure lucene saturation, 1 => pure log-TF saturation\n      tf_log_k: float = 1.0     # higher => weaker log compression\n  \n      epsilon: float = 1e-9\n      max_idf: float = float(\"inf\")\n      min_idf: float = 0.0\nwith:\n  class EvolvedParameters:\n      \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\n      delta: float = 0.5\n      alpha: float = 1.0\n      beta: float = 1.0\n  \n      # Light document-level priors\n      gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n  \n      # Frequent-term recall rescue (bounded)\n      common_strength: float = 0.25\n      common_pivot: float = 2.5\n  \n      # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n      coord_beta: float = 0.55\n  \n      # Burstiness-aware TF compression, but now made *rarity-adaptive* (protects recall for rare t...\n      tf_log_mix: float = 0.35  # base strength (still used, but gated by rarity)\n      tf_log_k: float = 1.0     # higher => weaker log compression\n      tf_mix_idf_pivot: float = 2.2   # lucene-idf pivot: above this => little/no log compression\n      tf_mix_idf_sharp: float = 1.0   # larger => sharper transition around pivot\n  \n      # Restore helpful TF blend for long/noisy docs\n      tf_salience_alpha: float = 0.35  # 0 => ignore salience; 1 => only salience\n  \n      epsilon: float = 1e-9\n      max_idf: float = float(\"inf\")\n  ... (1 more lines)\nChange 2: Replace:\n  class ScoringPrimitives:\n      \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n  \n      @staticmethod\n      def saturate_logtf_lucene(tf: float, k1: float, norm: float, k: float) -> float:\nwith:\n  class ScoringPrimitives:\n      \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n  \n      @staticmethod\n      def tf_salience(tf: float, dl: float, avgdl: float) -> float:\n          \"\"\"\n          Length-aware TF salience: downweights inflated TF in long docs.\n          Works as a smooth alternative evidence channel to protect recall.\n          \"\"\"\n          denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n          return tf / (denom + EvolvedParameters.epsilon)\n  \n      @staticmethod\n      def tf_salience_vectorized(\n          tf: NDArray[np.float64], dl: NDArray[np.float64], avgdl: float\n      ) -> NDArray[np.float64]:\n          denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n          return tf / (denom + EvolvedParameters.epsilon)\n  \n      @staticmethod\n      def saturate_logtf_lucene(tf: float, k1: float, norm: float, k: float) -> float:\nChange 3: Replace:\n  class TermScorer:\n      \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n  \n      @staticmethod\n      def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n          if tf <= 0:\n              return 0.0\n          k1, b = EvolvedParameters.k1, EvolvedParameters.b\n          idf = ScoringPrimitives.idf_lucene(df, N)\n          idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n          norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n  \n          mix = max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix)))\n          tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n          tf_logsat = ScoringPrimitives.saturate_logtf_lucene(\n              tf, k1, norm, EvolvedParameters.tf_log_k\n          )\n          tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n  \n          rescue = ScoringPrimitives.commonness_rescue(\n              idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n          )\n          return idf * tf_comp * rescue\nwith:\n  class TermScorer:\n      \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n  \n      @staticmethod\n      def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n          if tf <= 0:\n              return 0.0\n          k1, b = EvolvedParameters.k1, EvolvedParameters.b\n          idf = ScoringPrimitives.idf_lucene(df, N)\n          idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n          norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n  \n          # Rarity-adaptive burstiness handling:\n          # - rare terms (high idf): keep mostly standard saturation (protect recall)\n          # - common terms (low idf): allow more log-TF compression (reduce noisy bursts)\n          base_mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n          pivot = float(EvolvedParameters.tf_mix_idf_pivot)\n          sharp = float(max(EvolvedParameters.epsilon, EvolvedParameters.tf_mix_idf_sharp))\n          gate = 1.0 / (1.0 + math.exp((idf - pivot) / sharp))  # high for common terms\n          mix = base_mix * gate\n  \n          tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n          tf_logsat = ScoringPrimitives.saturate_logtf_lucene(tf, k1, norm, EvolvedParameters.tf_lo...\n          tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n  \n          # Add a second evidence channel that is robust for long docs.\n          a = float(max(0.0, min(1.0, float(EvolvedParameters.tf_salience_alpha))))\n          tf_sal = ScoringPrimitives.tf_salience(tf, dl, avgdl)\n          tf_comp = (1.0 - a) * tf_comp + a * tf_sal\n  \n  ... (4 more lines)\nChange 4: Replace:\n  norms = self.corpus.norm_array[candidate_docs]\n          scores = np.zeros(len(candidate_docs), dtype=np.float64)\n          matched = np.zeros(len(candidate_docs), dtype=np.float64)\n  \n          k1 = EvolvedParameters.k1\n          mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n          for i, term_id in enumerate(query_term_ids):\n              idf = self.corpus.idf_array[term_id]\n              if idf <= 0:\n                  continue\n              idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n  \n              rescue = ScoringPrimitives.commonness_rescue(\n                  float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n              )\n  \n              weight = query_term_weights[i] if query_term_weights is not None else 1.0\n              tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n              matched += (tf_row > 0).astype(np.float64)\n  \n              tf_sat = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n              tf_logsat = ScoringPrimitives.saturate_logtf_lucene_vectorized(\n                  tf_row, k1, norms, EvolvedParameters.tf_log_k\n              )\n              tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n              scores += weight * idf * rescue * tf_comp\nwith:\n  norms = self.corpus.norm_array[candidate_docs]\n          dls = self.corpus.doc_lengths[candidate_docs]\n          avgdl = self.corpus.avgdl\n  \n          scores = np.zeros(len(candidate_docs), dtype=np.float64)\n          matched = np.zeros(len(candidate_docs), dtype=np.float64)\n  \n          k1 = EvolvedParameters.k1\n          base_mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n          pivot = float(EvolvedParameters.tf_mix_idf_pivot)\n          sharp = float(max(EvolvedParameters.epsilon, EvolvedParameters.tf_mix_idf_sharp))\n          sal_a = float(max(0.0, min(1.0, float(EvolvedParameters.tf_salience_alpha))))\n  \n          for i, term_id in enumerate(query_term_ids):\n              idf = float(self.corpus.idf_array[term_id])\n              if idf <= 0:\n                  continue\n              idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n  \n              rescue = ScoringPrimitives.commonness_rescue(\n                  idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n              )\n  \n              weight = query_term_weights[i] if query_term_weights is not None else 1.0\n              tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n              present = (tf_row > 0).astype(np.float64)\n              matched += present\n  \n              # Rarity-adaptive mix (same logic as TermScorer, vectorized)\n              gate = 1.0 / (1.0 + math.exp((idf - pivot) / sharp))\n  ... (13 more lines)", "parent_metrics": {"beir_nfcorpus_ndcg@10": 0.31314307030822114, "beir_nfcorpus_recall@100": 0.25251845924222494, "beir_nfcorpus_index_time_ms": 3499.6753329760395, "beir_nfcorpus_query_time_ms": 145.22020902950317, "beir_scifact_ndcg@10": 0.6712888127283247, "beir_scifact_recall@100": 0.9246666666666666, "beir_scifact_index_time_ms": 4724.324125039857, "beir_scifact_query_time_ms": 556.7928340169601, "bright_pony_ndcg@10": 0.1374373689557774, "bright_pony_recall@100": 0.3340764784509166, "bright_pony_index_time_ms": 1330.5647920351475, "bright_pony_query_time_ms": 789.3992920289747, "beir_arguana_ndcg@10": 0.26511513844098455, "beir_arguana_recall@100": 0.8836545324768023, "beir_arguana_index_time_ms": 5690.302166040055, "beir_arguana_query_time_ms": 36243.881207949016, "bright_theoremqa_theorems_ndcg@10": 0.035010870079245165, "bright_theoremqa_theorems_recall@100": 0.14035087719298245, "bright_theoremqa_theorems_index_time_ms": 10429.570125008468, "bright_theoremqa_theorems_query_time_ms": 1472.6421249797568, "beir_scidocs_ndcg@10": 0.14374533232249212, "beir_scidocs_recall@100": 0.3354333333333334, "beir_scidocs_index_time_ms": 19364.24399999669, "beir_scidocs_query_time_ms": 4730.812082998455, "bright_economics_ndcg@10": 0.13886995662431437, "bright_economics_recall@100": 0.37012046131924675, "bright_economics_index_time_ms": 13835.945708968211, "bright_economics_query_time_ms": 4123.271416989155, "bright_biology_ndcg@10": 0.25098055815234677, "bright_biology_recall@100": 0.5021617087278815, "bright_biology_index_time_ms": 14681.578708987217, "bright_biology_query_time_ms": 3867.0919580035843, "beir_fiqa_ndcg@10": 0.22759271210535365, "beir_fiqa_recall@100": 0.5224152091050239, "beir_fiqa_index_time_ms": 32561.643499997444, "beir_fiqa_query_time_ms": 8464.979042008054, "bright_earth_science_ndcg@10": 0.33183754716779645, "bright_earth_science_recall@100": 0.6415581878546942, "bright_earth_science_index_time_ms": 30392.5277920207, "bright_earth_science_query_time_ms": 6470.952124975156, "bright_stackoverflow_ndcg@10": 0.17523301359412446, "bright_stackoverflow_recall@100": 0.4374814661394866, "bright_stackoverflow_index_time_ms": 97432.59241600754, "bright_stackoverflow_query_time_ms": 14760.791999986395, "beir_trec-covid_ndcg@10": 0.6162947865225128, "beir_trec-covid_recall@100": 0.10027061652041919, "beir_trec-covid_index_time_ms": 132869.15412498638, "beir_trec-covid_query_time_ms": 1957.2586250142194, "avg_ndcg@10": 0.27554576391679114, "avg_recall@100": 0.4537256664191398, "combined_score": 0.41808968591867013, "total_index_time_ms": 366812.12279206375, "total_query_time_ms": 83583.09291797923, "total_time_ms": 450395.215710043, "datasets_evaluated": 12, "datasets_failed": 0, "error": 0.0}, "island": 1}, "prompts": {"diff_user": {"system": "You are evolving a LEXICAL RETRIEVAL algorithm. The goal is discovery of new IR methods\u2014invent new algorithms, not just recombine existing primitives.\n\n## View: Primitives + Structure\nLexical retrieval in this codebase is PRIMITIVES (atoms) + STRUCTURE (how they combine).\n- Primitives: IDF, TF, saturation, length norm, aggregation (weighted sum, means, etc.).\n- Structure: how term scores become doc scores, how the pipeline is organized.\nThe seed is one structure (BM25-like). You can change parameters, add or invent new primitives, change formulas, or change structure. Prefer inventing new formulas or new primitives over only swapping which existing primitive is used where.\n\n## Evaluation Metrics\nPer dataset: nDCG@10, Recall@100, index_time_ms, query_time_ms.\nAggregate: avg_ndcg@10, avg_recall@100, combined_score = 0.8*avg_recall@100 + 0.2*avg_ndcg@10 (used to rank solutions).\nUse per-dataset metrics to find weak spots.\n\n## Evolution Targets (bm25_composable_fast.py)\n\n### 1. EvolvedParameters\nNumeric constants: k1, b, k3, delta, alpha, beta, gamma, epsilon, max_idf, min_idf. Change or add parameters via SEARCH/REPLACE.\n\n### 2. ScoringPrimitives\nAtoms: idf_* (classic, lucene, atire, bm25plus, smooth), tf_* (raw, log, double_log, boolean, augmented), saturate_* (basic, lucene, bm25, bm25l, bm25plus, log), length_norm_* (bm25, pivot, log), multiply, add, weighted_sum, geometric_mean, harmonic_mean, soft_max, query_weight_*, coverage_bonus, rarity_boost.\nYou can add new primitives with new formulas (e.g. a new saturation curve, a new IDF variant). Invent when it might help; don\u2019t limit yourself to recombining only what\u2019s there.\n\n### 3. TermScorer.score(tf, df, N, dl, avgdl)\nOne term\u2019s contribution. Evolve the formula: new combination of primitives or new math (e.g. asymmetric term importance, different saturation).\n\n### 4. DocumentScorer.score(term_scores, query_weights, matched_count, total_query_terms)\nAggregate term scores into doc score. Evolve aggregation or add terms (e.g. coverage, rarity).\n\n### 5. QueryProcessor.process(query) \u2192 (terms, weights)\nEvolve how the query is interpreted (weighting, dedup).\n\n### 6. score_kernel(query, doc_idx, corpus)\nFull pipeline. You can restructure it (e.g. different flow, use DocumentScorer here, or a different orchestration).\n\n## Guidelines\n- Invent new formulas or new primitives when it might improve retrieval; recombination alone is not the goal.\n- Keep interface compatibility: BM25(corpus).rank(query) and the Corpus/BM25 API must still work for the evaluator.\n- Preserve numerical stability (epsilon, safe division).\n- Use SEARCH/REPLACE diffs; SEARCH must exactly match the current program.\n- If you add vectorized primitives (e.g. for Corpus.idf_array / norm_array), add a *_vectorized variant in ScoringPrimitives and use it in BM25._score_candidates_vectorized so batch ranking stays consistent with score_kernel.\n", "user": "# Current Program Information\n- Fitness: 0.4181\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.4206 \u2192 0.4181. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace:\n  class EvolvedParameters:\n      \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\n      delta: float = 0.5\n      alpha: float = 1.0\n      beta: float = 1.0\n  \n      # Light document-level priors\n      gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n  \n      # Frequent-term recall rescue (bounded)\n      common_strength: float = 0.25\n      common_pivot: float = 2.5\n  \n      # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n      coord_beta: float = 0.55\n  \n      epsilon: float = 1e-9\n      max_idf: float = float(\"inf\")\n      min_idf: float = 0.0\nwith:\n  class EvolvedParameters:\n      \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\n      delta: float = 0.5\n  \n      # Light document-level priors\n      gamma: float = 0.20  # slight trim; early-hit bonus will add back targeted ranking signal\n  \n      # Frequent-term recall rescue (bounded)\n      common_strength: float = 0.25\n      common_pivot: float = 2.5\n  \n      # Rarity-aware coordination (soft AND weighted by query-term rarity)\n      coord_beta: float = 0.55\n  \n      # New: early-hit proximity surrogate (cheap, no positional index)\n      early_strength: float = 0.10\n      early_window: int = 64        # consider only first W tokens for \"early\" evidence\n      early_cover_beta: float = 1.3 # gate by coverage^beta so 1-term matches don't get over-boosted\n  \n      epsilon: float = 1e-9\n      max_idf: float = float(\"inf\")\n      min_idf: float = 0.0\nChange 2: Replace:\n  class ScoringPrimitives:\n      \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\nwith:\n  class ScoringPrimitives:\n      \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n  \n      @staticmethod\n      def early_hit_bonus(min_pos: int | None, window: int) -> float:\n          \"\"\"\n          New primitive: cheap proximity/field surrogate from *first occurrence position*.\n          - If a query term appears early, it is often a title/abstract-like signal.\n          - window limits the effect to early tokens; outside window => 0.\n          Returns in [0,1]: 1/(1+pos) if pos in [0, window), else 0.\n          \"\"\"\n          if min_pos is None or min_pos < 0 or min_pos >= window:\n              return 0.0\n          return 1.0 / (1.0 + float(min_pos))\nChange 3: Replace:\n  def score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n      \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n      if not query:\n          return 0.0\n      query_terms, query_weights = QueryProcessor.process(query)\n      if not query_terms:\n          return 0.0\n  \n      doc_tf = corpus.get_term_frequencies(doc_idx)\n      dl = corpus.doc_lengths[doc_idx]\n      avgdl = corpus.avgdl\n      N = corpus.N\n  \n      term_scores: list[float] = []\n      used_weights: list[float] = []\n      matched_count = 0\n  \n      # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n      total_rarity = 0.0\n      matched_rarity = 0.0\n      for term in query_terms:\n          df = corpus.get_df(term)\n          total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n  \n      for term, w in zip(query_terms, query_weights, strict=False):\n          tf = doc_tf.get(term, 0)\n          if tf > 0:\n              matched_count += 1\n              df = corpus.get_df(term)\n              term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n  ... (11 more lines)\nwith:\n  def score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n      \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n      if not query:\n          return 0.0\n      query_terms, query_weights = QueryProcessor.process(query)\n      if not query_terms:\n          return 0.0\n  \n      doc_tf = corpus.get_term_frequencies(doc_idx)\n      dl = corpus.doc_lengths[doc_idx]\n      avgdl = corpus.avgdl\n      N = corpus.N\n  \n      term_scores: list[float] = []\n      used_weights: list[float] = []\n      matched_count = 0\n  \n      # New: early-hit doc prior (computed from token stream; no positional index needed)\n      early_sum = 0.0\n      early_wsum = 0.0\n      if EvolvedParameters.early_strength > 0:\n          tokens = corpus.documents[doc_idx]\n          window = max(1, int(EvolvedParameters.early_window))\n          # Build first-position map for only the early window for speed\n          first_pos: dict[str, int] = {}\n          for i, t in enumerate(tokens[:window]):\n              if t not in first_pos:\n                  first_pos[t] = i\n  \n      # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n  ... (36 more lines)\nChange 4: Replace:\n  # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n          if EvolvedParameters.coord_beta > 0 and qn > 0:\n              # balanced rarity per query term (bounded)\n              df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n              rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n              rarity_q = np.maximum(rarity_q, 0.0)\n              total_rarity = float(np.sum(rarity_q))\n              if total_rarity > 0:\n                  # matched_rarity: sum rarity of query terms present in doc\n                  matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                  for i, term_id in enumerate(query_term_ids):\n                      tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                      matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n  \n                  scores *= np.power(\n                      np.maximum(matched_rarity / total_rarity, 0.0),\n                      EvolvedParameters.coord_beta,\n                  )\n  \n          return scores\nwith:\n  # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n          if EvolvedParameters.coord_beta > 0 and qn > 0:\n              # balanced rarity per query term (bounded)\n              df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n              rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n              rarity_q = np.maximum(rarity_q, 0.0)\n              total_rarity = float(np.sum(rarity_q))\n              if total_rarity > 0:\n                  # matched_rarity: sum rarity of query terms present in doc\n                  matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                  for i, term_id in enumerate(query_term_ids):\n                      tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                      matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n  \n                  scores *= np.power(\n                      np.maximum(matched_rarity / total_rarity, 0.0),\n                      EvolvedParameters.coord_beta,\n                  )\n  \n          # Early-hit bonus (post-hoc; keeps consistent with score_kernel)\n          if EvolvedParameters.early_strength > 0 and qn > 0:\n              window = max(1, int(EvolvedParameters.early_window))\n              qweights = query_term_weights if query_term_weights is not None else np.ones(len(quer...\n  \n              # coverage gate from already computed matched\n              coverage = matched / qn\n              gate = np.power(coverage, max(0.0, float(EvolvedParameters.early_cover_beta)))\n  \n              early = np.zeros(len(candidate_docs), dtype=np.float64)\n              wsum = float(np.sum(qweights)) + EvolvedParameters.epsilon\n  ... (18 more lines)\n- Metrics: beir_nfcorpus_ndcg@10: 0.3136, beir_nfcorpus_recall@100: 0.2526, beir_nfcorpus_index_time_ms: 3485.4698, beir_nfcorpus_query_time_ms: 1911.5743, bright_pony_ndcg@10: 0.1357, bright_pony_recall@100: 0.3358, bright_pony_index_time_ms: 1490.9817, bright_pony_query_time_ms: 4952.1225, beir_scifact_ndcg@10: 0.6757, beir_scifact_recall@100: 0.9247, beir_scifact_index_time_ms: 4806.7429, beir_scifact_query_time_ms: 8728.8354, beir_arguana_ndcg@10: 0.2586, beir_arguana_recall@100: 0.8772, beir_arguana_index_time_ms: 5875.8071, beir_arguana_query_time_ms: 188053.1643, bright_theoremqa_theorems_ndcg@10: 0.0328, bright_theoremqa_theorems_recall@100: 0.1469, bright_theoremqa_theorems_index_time_ms: 10487.0187, bright_theoremqa_theorems_query_time_ms: 12658.7517, beir_scidocs_ndcg@10: 0.1420, beir_scidocs_recall@100: 0.3352, beir_scidocs_index_time_ms: 19629.8387, beir_scidocs_query_time_ms: 106867.2750, bright_economics_ndcg@10: 0.1331, bright_economics_recall@100: 0.3680, bright_economics_index_time_ms: 13926.8271, bright_economics_query_time_ms: 24660.5844, bright_biology_ndcg@10: 0.2583, bright_biology_recall@100: 0.5387, bright_biology_index_time_ms: 14499.6342, bright_biology_query_time_ms: 31339.5724, bright_earth_science_ndcg@10: 0.3281, bright_earth_science_recall@100: 0.6466, bright_earth_science_index_time_ms: 31667.2844, bright_earth_science_query_time_ms: 53723.1652, beir_trec-covid_ndcg@10: 0.6247, beir_trec-covid_recall@100: 0.1009, beir_trec-covid_index_time_ms: 137169.2561, beir_trec-covid_query_time_ms: 45983.5261, bright_stackoverflow_ndcg@10: 0.1740, bright_stackoverflow_recall@100: 0.4371, bright_stackoverflow_index_time_ms: 99682.7822, bright_stackoverflow_query_time_ms: 93263.4285, beir_fiqa_ndcg@10: 0.2216, beir_fiqa_recall@100: 0.5206, beir_fiqa_index_time_ms: 33879.9398, beir_fiqa_query_time_ms: 181470.2380, avg_ndcg@10: 0.2748, avg_recall@100: 0.4570, combined_score: 0.4206, total_index_time_ms: 376601.5827, total_query_time_ms: 753612.2378, total_time_ms: 1130213.8205, datasets_evaluated: 12.0000, datasets_failed: 0.0000, error: 0.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace:\n  class EvolvedParameters:\n      \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\n      delta: float = 0.5\n      alpha: float = 1.0\n      beta: float = 1.0\n  \n      # Light document-level priors\n      gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n  \n      # Frequent-term recall rescue (bounded)\n      common_strength: float = 0.25\n      common_pivot: float = 2.5\n  \n      # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n      coord_beta: float = 0.55\n  \n      epsilon: float = 1e-9\n      max_idf: float = float(\"inf\")\n      min_idf: float = 0.0\nwith:\n  class EvolvedParameters:\n      \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\n      delta: float = 0.5\n      alpha: float = 1.0\n      beta: float = 1.0\n  \n      # Light document-level priors\n      gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n  \n      # Frequent-term recall rescue (bounded)\n      common_strength: float = 0.25\n      common_pivot: float = 2.5\n  \n      # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n      coord_beta: float = 0.55\n  \n      # New: informativeness gate (bounded, smooth) to reduce ultra-rare spikes + ignore near-stopw...\n      info_pivot: float = 2.0   # pivot in balanced-idf space\n      info_strength: float = 0.45  # how much the gate can amplify informative terms\n      info_floor: float = 0.70  # minimum multiplier (prevents killing recall)\n  \n      epsilon: float = 1e-9\n      max_idf: float = float(\"inf\")\n      min_idf: float = 0.0\nChange 2: Replace:\n  class ScoringPrimitives:\n      \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n  \n      @staticmethod\n      def idf_balanced(df: float, N: int) -> float:\nwith:\n  class ScoringPrimitives:\n      \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n  \n      @staticmethod\n      def informativeness_gate(idf_bal: float, pivot: float, strength: float, floor: float) -> float:\n          \"\"\"\n          New primitive: bounded informativeness multiplier in [floor, floor+strength].\n          Uses balanced-idf (less spiky than lucene idf) and tanh compression.\n          - Very common terms => ~floor\n          - Moderately informative => rises smoothly\n          - Ultra-rare => saturates (prevents domination)\n          \"\"\"\n          f = max(0.0, min(1.0, floor))\n          s = max(0.0, strength)\n          x = (idf_bal - pivot) / (pivot + EvolvedParameters.epsilon)\n          return f + s * (0.5 + 0.5 * math.tanh(x))\n  \n      @staticmethod\n      def informativeness_gate_vectorized(\n          idf_bal: NDArray[np.float64], pivot: float, strength: float, floor: float\n      ) -> NDArray[np.float64]:\n          f = float(max(0.0, min(1.0, floor)))\n          s = float(max(0.0, strength))\n          x = (idf_bal - pivot) / (pivot + EvolvedParameters.epsilon)\n          return f + s * (0.5 + 0.5 * np.tanh(x))\n  \n      @staticmethod\n      def idf_balanced(df: float, N: int) -> float:\nChange 3: Replace:\n  class TermScorer:\n      \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n  \n      @staticmethod\n      def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n          if tf <= 0:\n              return 0.0\n          k1, b = EvolvedParameters.k1, EvolvedParameters.b\n          idf = ScoringPrimitives.idf_lucene(df, N)\n          idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n          norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n          tf_comp = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n  \n          rescue = ScoringPrimitives.commonness_rescue(\n              idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n          )\n          return idf * tf_comp * rescue\nwith:\n  class TermScorer:\n      \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n  \n      @staticmethod\n      def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n          if tf <= 0:\n              return 0.0\n          k1, b = EvolvedParameters.k1, EvolvedParameters.b\n  \n          idf = ScoringPrimitives.idf_lucene(df, N)\n          idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n  \n          # Use balanced idf only as a *gate driver* (bounded), not as the main magnitude.\n          idf_bal = ScoringPrimitives.idf_balanced(df, N)\n          info = ScoringPrimitives.informativeness_gate(\n              idf_bal,\n              EvolvedParameters.info_pivot,\n              EvolvedParameters.info_strength,\n              EvolvedParameters.info_floor,\n          )\n  \n          norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n          tf_comp = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n  \n          rescue = ScoringPrimitives.commonness_rescue(\n              idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n          )\n          return idf * tf_comp * rescue * info\nChange 4: Replace:\n  k1 = EvolvedParameters.k1\n          for i, term_id in enumerate(query_term_ids):\n              idf = self.corpus.idf_array[term_id]\n              if idf <= 0:\n                  continue\n              idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n  \n              rescue = ScoringPrimitives.commonness_rescue(\n                  float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n              )\n  \n              weight = query_term_weights[i] if query_term_weights is not None else 1.0\n              tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n              matched += (tf_row > 0).astype(np.float64)\n  \n              tf_saturated = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n              scores += weight * idf * rescue * tf_saturated\nwith:\n  k1 = EvolvedParameters.k1\n          for i, term_id in enumerate(query_term_ids):\n              idf = self.corpus.idf_array[term_id]\n              if idf <= 0:\n                  continue\n              idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n  \n              rescue = ScoringPrimitives.commonness_rescue(\n                  float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n              )\n  \n              # Informativeness gate (bounded), driven by balanced-idf.\n              df_t = float(self.corpus._df[term_id])\n              idf_bal = ScoringPrimitives.idf_balanced(df_t, self.corpus.N)\n              info = ScoringPrimitives.informativeness_gate(\n                  idf_bal,\n                  EvolvedParameters.info_pivot,\n                  EvolvedParameters.info_strength,\n                  EvolvedParameters.info_floor,\n              )\n  \n              weight = query_term_weights[i] if query_term_weights is not None else 1.0\n              tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n              matched += (tf_row > 0).astype(np.float64)\n  \n              tf_saturated = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n              scores += weight * idf * rescue * info * tf_saturated\n- Metrics: beir_nfcorpus_ndcg@10: 0.3135, beir_nfcorpus_recall@100: 0.2544, beir_nfcorpus_index_time_ms: 3492.8307, beir_nfcorpus_query_time_ms: 136.7948, beir_scifact_ndcg@10: 0.6766, beir_scifact_recall@100: 0.9280, beir_scifact_index_time_ms: 4717.7408, beir_scifact_query_time_ms: 524.0140, bright_pony_ndcg@10: 0.1374, bright_pony_recall@100: 0.3362, bright_pony_index_time_ms: 1439.5825, bright_pony_query_time_ms: 698.9180, beir_arguana_ndcg@10: 0.2675, beir_arguana_recall@100: 0.8922, beir_arguana_index_time_ms: 5718.9641, beir_arguana_query_time_ms: 30917.3652, bright_theoremqa_theorems_ndcg@10: 0.0348, bright_theoremqa_theorems_recall@100: 0.1404, bright_theoremqa_theorems_index_time_ms: 10378.8810, bright_theoremqa_theorems_query_time_ms: 1252.0383, beir_scidocs_ndcg@10: 0.1440, beir_scidocs_recall@100: 0.3360, beir_scidocs_index_time_ms: 19044.9004, beir_scidocs_query_time_ms: 4236.1484, bright_economics_ndcg@10: 0.1350, bright_economics_recall@100: 0.3587, bright_economics_index_time_ms: 13514.0485, bright_economics_query_time_ms: 3510.8285, bright_biology_ndcg@10: 0.2629, bright_biology_recall@100: 0.5298, bright_biology_index_time_ms: 14682.6185, bright_biology_query_time_ms: 3360.5938, beir_fiqa_ndcg@10: 0.2239, beir_fiqa_recall@100: 0.5213, beir_fiqa_index_time_ms: 32486.5020, beir_fiqa_query_time_ms: 7111.0440, bright_earth_science_ndcg@10: 0.3321, bright_earth_science_recall@100: 0.6504, bright_earth_science_index_time_ms: 30947.4680, bright_earth_science_query_time_ms: 5672.8213, bright_stackoverflow_ndcg@10: 0.1724, bright_stackoverflow_recall@100: 0.4415, bright_stackoverflow_index_time_ms: 98303.4775, bright_stackoverflow_query_time_ms: 12566.7329, beir_trec-covid_ndcg@10: 0.6144, beir_trec-covid_recall@100: 0.1016, beir_trec-covid_index_time_ms: 131536.9812, beir_trec-covid_query_time_ms: 1731.7452, avg_ndcg@10: 0.2762, avg_recall@100: 0.4575, combined_score: 0.4213, total_index_time_ms: 366263.9954, total_query_time_ms: 71719.0444, total_time_ms: 437983.0398, datasets_evaluated: 12.0000, datasets_failed: 0.0000, error: 0.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace:\n  class EvolvedParameters:\n      \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\n      delta: float = 0.5\n  \n      # Restored high-performing knobs (Program 1/2 lineage)\n      alpha: float = 0.6   # TF blending weight\n      beta: float = 0.35   # coordination strength\n      gamma: float = 0.05  # mild rare-term shaping\n  \n      # Keep experimental knobs defined (prevents runtime failure if referenced)\n      idf_pivot: float = 3.0\n      cov_power: float = 2.0\n  \n      epsilon: float = 1e-9\n      max_idf: float = float(\"inf\")\n      min_idf: float = 0.0\nwith:\n  class EvolvedParameters:\n      \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n      k1: float = 0.9\n      b: float = 0.4\n      k3: float = 8.0\n      delta: float = 0.5\n  \n      # TF blending (keep; tends to help long/noisy docs)\n      alpha: float = 0.6\n  \n      # Additive recall-friendly coverage bonus (helps recall@100 without harsh AND)\n      gamma: float = 0.22\n  \n      # Frequent-term recall rescue (bounded)\n      common_strength: float = 0.25\n      common_pivot: float = 2.5\n  \n      # Rarity-aware coordination (soft AND), bounded to protect recall\n      coord_beta: float = 0.55\n      coord_floor: float = 0.35\n  \n      epsilon: float = 1e-9\n      max_idf: float = float(\"inf\")\n      min_idf: float = 0.0\nChange 2: Replace:\n  class ScoringPrimitives:\n      \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n  \n      @staticmethod\n      def idf_classic(df: float, N: int) -> float:\n          return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\nwith:\n  class ScoringPrimitives:\n      \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n  \n      @staticmethod\n      def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n          \"\"\"\n          Boost frequent terms a bit (low idf), bounded and smooth.\n          When idf << pivot => multiplier ~ 1 + strength\n          When idf >> pivot => multiplier ~ 1\n          \"\"\"\n          return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n  \n      @staticmethod\n      def commonness_rescue_vectorized(\n          idf: NDArray[np.float64], strength: float, pivot: float\n      ) -> NDArray[np.float64]:\n          return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n  \n      @staticmethod\n      def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n          if total_query_terms <= 0:\n              return 0.0\n          c = matched_terms / total_query_terms\n          return c * c\n  \n      @staticmethod\n      def coord_rarity_aware(\n          matched_rarity: float, total_rarity: float, beta: float, floor: float\n      ) -> float:\n          \"\"\"\n  ... (23 more lines)\nChange 3: Replace:\n  class TermScorer:\n      \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n  \n      @staticmethod\n      def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n          if tf <= 0:\n              return 0.0\n          k1, b = EvolvedParameters.k1, EvolvedParameters.b\n  \n          # Robust IDF\n          idf = ScoringPrimitives.idf_balanced(df, N)\n          idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n  \n          norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n  \n          # Blend: classic Lucene BM25-like sat + length-aware salience\n          tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n          tf_sal = ScoringPrimitives.tf_salience(tf, dl, avgdl)\n          tf_comp = (1.0 - EvolvedParameters.alpha) * tf_sat + EvolvedParameters.alpha * tf_sal\n  \n          # Mild rare-term shaping (kept small)\n          if EvolvedParameters.gamma > 0:\n              tf_comp *= (1.0 + EvolvedParameters.gamma * math.tanh(idf))\n  \n          return idf * tf_comp\nwith:\n  class TermScorer:\n      \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n  \n      @staticmethod\n      def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n          if tf <= 0:\n              return 0.0\n          k1, b = EvolvedParameters.k1, EvolvedParameters.b\n  \n          # Strong default IDF\n          idf = ScoringPrimitives.idf_lucene(df, N)\n          idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n  \n          norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n  \n          # TF: keep your blend (often helps for long docs / bursty tf)\n          tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n          tf_sal = ScoringPrimitives.tf_salience(tf, dl, avgdl)\n          tf_comp = (1.0 - EvolvedParameters.alpha) * tf_sat + EvolvedParameters.alpha * tf_sal\n  \n          rescue = ScoringPrimitives.commonness_rescue(\n              idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n          )\n          return idf * tf_comp * rescue\nChange 4: Replace:\n  class DocumentScorer:\n      \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n  \n      @staticmethod\n      def score(\n          term_scores: list[float],\n          query_weights: list[float],\n          matched_count: int,\n          total_query_terms: int,\n      ) -> float:\n          if not term_scores:\n              return 0.0\n  \n          base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n  \n          coord = ScoringPrimitives.coord_factor(\n              matched_count, total_query_terms, EvolvedParameters.beta\n          )\n          return base * coord\nwith:\n  class DocumentScorer:\n      \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n  \n      @staticmethod\n      def score(\n          term_scores: list[float],\n          query_weights: list[float],\n          matched_count: int,\n          total_query_terms: int,\n          matched_rarity: float = 0.0,\n          total_rarity: float = 0.0,\n      ) -> float:\n          if not term_scores:\n              return 0.0\n  \n          base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n  \n          # Additive coverage bonus keeps recall strong\n          if EvolvedParameters.gamma > 0:\n              base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                  matched_count, total_query_terms\n              )\n  \n          # Bounded rarity-aware coordination improves early precision without killing recall\n          if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n              base *= ScoringPrimitives.coord_rarity_aware(\n                  matched_rarity,\n                  total_rarity,\n                  EvolvedParameters.coord_beta,\n                  EvolvedParameters.coord_floor,\n  ... (3 more lines)\nChange 5: Replace:\n  def score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n      \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n      if not query:\n          return 0.0\n      query_terms, query_weights = QueryProcessor.process(query)\n      if not query_terms:\n          return 0.0\n      doc_tf = corpus.get_term_frequencies(doc_idx)\n      dl = corpus.doc_lengths[doc_idx]\n      avgdl = corpus.avgdl\n      N = corpus.N\n  \n      term_scores: list[float] = []\n      used_weights: list[float] = []\n      matched_count = 0\n  \n      for term, w in zip(query_terms, query_weights, strict=False):\n          tf = doc_tf.get(term, 0)\n          if tf > 0:\n              matched_count += 1\n              df = corpus.get_df(term)\n              term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n              used_weights.append(w)\n  \n      return DocumentScorer.score(term_scores, used_weights, matched_count, len(query_terms))\nwith:\n  def score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n      \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n      if not query:\n          return 0.0\n      query_terms, query_weights = QueryProcessor.process(query)\n      if not query_terms:\n          return 0.0\n      doc_tf = corpus.get_term_frequencies(doc_idx)\n      dl = corpus.doc_lengths[doc_idx]\n      avgdl = corpus.avgdl\n      N = corpus.N\n  \n      term_scores: list[float] = []\n      used_weights: list[float] = []\n      matched_count = 0\n  \n      # rarity-mass coverage tracking (bounded rarity; reduces ultra-rare dominance)\n      total_rarity = 0.0\n      matched_rarity = 0.0\n      for term in query_terms:\n          df = corpus.get_df(term)\n          total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n  \n      for term, w in zip(query_terms, query_weights, strict=False):\n          tf = doc_tf.get(term, 0)\n          if tf > 0:\n              matched_count += 1\n              df = corpus.get_df(term)\n              term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n              used_weights.append(w)\n  ... (10 more lines)\nChange 6: Replace:\n  # Match TermScorer: balanced IDF for robustness across datasets\n          self.idf_array = ScoringPrimitives.idf_balanced_vectorized(self._df, self.N)\nwith:\n  # Match TermScorer: lucene IDF array for fast vectorized scoring\n          self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\nChange 7: Replace:\n  def _score_candidates_vectorized(\n          self,\n          query_term_ids: list[int],\n          candidate_docs: NDArray[np.int64],\n          query_term_weights: NDArray[np.float64] | None = None,\n      ) -> NDArray[np.float64]:\n          if len(candidate_docs) == 0:\n              return np.array([], dtype=np.float64)\n  \n          norms = self.corpus.norm_array[candidate_docs]\n          dls = self.corpus.doc_lengths[candidate_docs]\n          avgdl = self.corpus.avgdl\n  \n          scores = np.zeros(len(candidate_docs), dtype=np.float64)\n          matched = np.zeros(len(candidate_docs), dtype=np.float64)\n  \n          k1 = EvolvedParameters.k1\n  \n          for i, term_id in enumerate(query_term_ids):\n              idf = float(self.corpus.idf_array[term_id])\n              if idf <= 0:\n                  continue\n              idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n  \n              weight = query_term_weights[i] if query_term_weights is not None else 1.0\n  \n              tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n              present = tf_row > 0\n              matched += present.astype(np.float64)\n  \n  ... (15 more lines)\nwith:\n  def _score_candidates_vectorized(\n          self,\n          query_term_ids: list[int],\n          candidate_docs: NDArray[np.int64],\n          query_term_weights: NDArray[np.float64] | None = None,\n      ) -> NDArray[np.float64]:\n          if len(candidate_docs) == 0:\n              return np.array([], dtype=np.float64)\n  \n          norms = self.corpus.norm_array[candidate_docs]\n          dls = self.corpus.doc_lengths[candidate_docs]\n          avgdl = self.corpus.avgdl\n  \n          scores = np.zeros(len(candidate_docs), dtype=np.float64)\n          matched = np.zeros(len(candidate_docs), dtype=np.float64)\n  \n          # rarity-mass tracking\n          matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n  \n          k1 = EvolvedParameters.k1\n          total_rarity = 0.0\n  \n          # Precompute bounded rarity per query term (balanced idf) for coordination\n          df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)] if query_term_ids else n...\n          rarity_q = (\n              ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N) if df_q.size else np.a...\n          )\n          rarity_q = np.maximum(rarity_q, 0.0)\n          total_rarity = float(np.sum(rarity_q)) if rarity_q.size else 0.0\n  \n  ... (41 more lines)\n- Metrics: beir_nfcorpus_ndcg@10: 0.3188, beir_nfcorpus_recall@100: 0.2550, beir_nfcorpus_index_time_ms: 3536.1952, beir_nfcorpus_query_time_ms: 104.8869, beir_scifact_ndcg@10: 0.6789, beir_scifact_recall@100: 0.9213, beir_scifact_index_time_ms: 4683.8895, beir_scifact_query_time_ms: 377.2150, bright_pony_ndcg@10: 0.1030, bright_pony_recall@100: 0.2884, bright_pony_index_time_ms: 1351.3467, bright_pony_query_time_ms: 478.1130, beir_arguana_ndcg@10: 0.2762, beir_arguana_recall@100: 0.9122, beir_arguana_index_time_ms: 5654.6724, beir_arguana_query_time_ms: 21414.3204, bright_theoremqa_theorems_ndcg@10: 0.0265, bright_theoremqa_theorems_recall@100: 0.1382, bright_theoremqa_theorems_index_time_ms: 10596.0036, bright_theoremqa_theorems_query_time_ms: 922.4393, beir_scidocs_ndcg@10: 0.1462, beir_scidocs_recall@100: 0.3437, beir_scidocs_index_time_ms: 19430.0675, beir_scidocs_query_time_ms: 3447.2729, bright_economics_ndcg@10: 0.1648, bright_economics_recall@100: 0.3891, bright_economics_index_time_ms: 13972.7823, bright_economics_query_time_ms: 2544.5837, bright_biology_ndcg@10: 0.2426, bright_biology_recall@100: 0.4889, bright_biology_index_time_ms: 14827.4495, bright_biology_query_time_ms: 2468.2880, beir_fiqa_ndcg@10: 0.2258, beir_fiqa_recall@100: 0.5279, beir_fiqa_index_time_ms: 32746.0572, beir_fiqa_query_time_ms: 6245.7120, bright_earth_science_ndcg@10: 0.3585, bright_earth_science_recall@100: 0.6521, bright_earth_science_index_time_ms: 30934.4683, bright_earth_science_query_time_ms: 3988.7256, bright_stackoverflow_ndcg@10: 0.1829, bright_stackoverflow_recall@100: 0.4559, bright_stackoverflow_index_time_ms: 97168.8703, bright_stackoverflow_query_time_ms: 9139.0520, beir_trec-covid_ndcg@10: 0.6603, beir_trec-covid_recall@100: 0.1062, beir_trec-covid_index_time_ms: 132465.0778, beir_trec-covid_query_time_ms: 1429.0537, avg_ndcg@10: 0.2820, avg_recall@100: 0.4566, combined_score: 0.4217, total_index_time_ms: 367366.8804, total_query_time_ms: 52559.6624, total_time_ms: 419926.5428, datasets_evaluated: 12.0000, datasets_failed: 0.0000, error: 0.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.4217)\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n\n    # TF blending (keep; tends to help long/noisy docs)\n    alpha: float = 0.6\n\n    # Additive recall-friendly coverage bonus (helps recall@100 without harsh AND)\n    gamma: float = 0.22\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # Rarity-aware coordination (soft AND), bounded to protect recall\n    coord_beta: float = 0.55\n    coord_floor: float = 0.35\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        c = matched_terms / total_query_terms\n        return c * c\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float, floor: float\n    ) -> float:\n        \"\"\"\n        Coordination based on rarity-mass coverage (soft AND), bounded for recall.\n        Returns: floor + (1-floor) * (matched_rarity/total_rarity)^beta\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        frac = max(0.0, matched_rarity) / t\n        f = max(0.0, min(1.0, floor))\n        return f + (1.0 - f) * (frac ** max(0.0, beta))\n\n    @staticmethod\n    def coord_rarity_aware_vectorized(\n        matched_rarity: NDArray[np.float64],\n        total_rarity: float,\n        beta: float,\n        floor: float,\n    ) -> NDArray[np.float64]:\n        t = max(float(total_rarity), EvolvedParameters.epsilon)\n        frac = np.maximum(matched_rarity, 0.0) / t\n        f = float(max(0.0, min(1.0, floor)))\n        return f + (1.0 - f) * np.power(frac, max(0.0, float(beta)))\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded, two-sided IDF: reduces ultra-rare spikes while still penalizing frequent terms.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def tf_salience(tf: float, dl: float, avgdl: float) -> float:\n        \"\"\"\n        Length-aware TF salience: downweights inflated TF in long docs.\n        \"\"\"\n        denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n        return tf / (denom + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def tf_salience_vectorized(\n        tf: NDArray[np.float64], dl: NDArray[np.float64], avgdl: float\n    ) -> NDArray[np.float64]:\n        denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n        return tf / (denom + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coord_factor(matched_terms: int, total_query_terms: int, beta: float) -> float:\n        \"\"\"\n        Soft coordination factor: (matched/total)^beta. Multiplies score.\n        \"\"\"\n        if total_query_terms <= 0 or matched_terms <= 0:\n            return 0.0\n        return (matched_terms / total_query_terms) ** max(beta, 0.0)\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def idf_mixed_compressed(df: float, N: int) -> float:\n        \"\"\"\n        New primitive: blend two IDFs then compress extremes.\n        Motivation: very rare terms can dominate nDCG@10; compression tends to improve\n        ranking robustness across heterogeneous BEIR/BRIGHT corpora while preserving recall.\n        \"\"\"\n        a = EvolvedParameters.alpha\n        idf_a = ScoringPrimitives.idf_lucene(df, N)\n        idf_b = ScoringPrimitives.idf_atire(df, N)\n        mixed = a * idf_a + (1.0 - a) * idf_b\n        # soft compression of very large idf values (keeps monotonicity)\n        p = EvolvedParameters.idf_pivot\n        beta = EvolvedParameters.beta\n        return mixed / (1.0 + beta * max(0.0, mixed - p))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_tflog_bm25(tf: float, k1: float, norm: float) -> float:\n        \"\"\"\n        New primitive: apply log-TF before BM25-style saturation.\n        Helps corpora with bursty term repetition (e.g., forum/stack traces) without\n        killing signals for single occurrences.\n        \"\"\"\n        if tf <= 0:\n            return 0.0\n        t = 1.0 + math.log(tf)\n        denom = t + k1 * norm + EvolvedParameters.epsilon\n        return (t * (k1 + 1.0)) / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        # more tunable than fixed square; tends to help nDCG@10 by preferring fuller matches\n        return coverage ** max(1.0, EvolvedParameters.cov_power)\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n\n        # Strong default IDF\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n\n        # TF: keep your blend (often helps for long docs / bursty tf)\n        tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n        tf_sal = ScoringPrimitives.tf_salience(tf, dl, avgdl)\n        tf_comp = (1.0 - EvolvedParameters.alpha) * tf_sat + EvolvedParameters.alpha * tf_sal\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # Bounded rarity-aware coordination improves early precision without killing recall\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity,\n                total_rarity,\n                EvolvedParameters.coord_beta,\n                EvolvedParameters.coord_floor,\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # rarity-mass coverage tracking (bounded rarity; reduces ultra-rare dominance)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    return DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        # Match TermScorer: lucene IDF array for fast vectorized scoring\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        dls = self.corpus.doc_lengths[candidate_docs]\n        avgdl = self.corpus.avgdl\n\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        # rarity-mass tracking\n        matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        total_rarity = 0.0\n\n        # Precompute bounded rarity per query term (balanced idf) for coordination\n        df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)] if query_term_ids else np.array([], dtype=np.float64)\n        rarity_q = (\n            ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N) if df_q.size else np.array([], dtype=np.float64)\n        )\n        rarity_q = np.maximum(rarity_q, 0.0)\n        total_rarity = float(np.sum(rarity_q)) if rarity_q.size else 0.0\n\n        for i, term_id in enumerate(query_term_ids):\n            idf = float(self.corpus.idf_array[term_id])\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            present = (tf_row > 0).astype(np.float64)\n            matched += present\n            if rarity_q.size:\n                matched_rarity += present * float(rarity_q[i])\n\n            tf_sat = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            tf_sal = ScoringPrimitives.tf_salience_vectorized(tf_row, dls, avgdl)\n            tf_comp = (1.0 - EvolvedParameters.alpha) * tf_sat + EvolvedParameters.alpha * tf_sal\n\n            scores += weight * idf * rescue * tf_comp\n\n        # Additive coverage bonus\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Bounded rarity-aware coordination\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            coord = ScoringPrimitives.coord_rarity_aware_vectorized(\n                matched_rarity,\n                total_rarity,\n                EvolvedParameters.coord_beta,\n                EvolvedParameters.coord_floor,\n            )\n            scores *= coord\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n        query_terms, query_weights = QueryProcessor.process(query)\n        query_term_ids = []\n        query_term_weights = []\n        for term, w in zip(query_terms, query_weights, strict=False):\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(float(w))\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\nKey features: Performs well on beir_nfcorpus_ndcg@10 (0.3188), Performs well on beir_nfcorpus_recall@100 (0.2550), Performs well on beir_nfcorpus_index_time_ms (3536.1952), Performs well on beir_nfcorpus_query_time_ms (104.8869), Performs well on beir_scifact_ndcg@10 (0.6789), Performs well on beir_scifact_recall@100 (0.9213), Performs well on beir_scifact_index_time_ms (4683.8895), Performs well on beir_scifact_query_time_ms (377.2150), Performs well on bright_pony_ndcg@10 (0.1030), Performs well on bright_pony_recall@100 (0.2884), Performs well on bright_pony_index_time_ms (1351.3467), Performs well on bright_pony_query_time_ms (478.1130), Performs well on beir_arguana_ndcg@10 (0.2762), Performs well on beir_arguana_recall@100 (0.9122), Performs well on beir_arguana_index_time_ms (5654.6724), Performs well on beir_arguana_query_time_ms (21414.3204), Performs well on bright_theoremqa_theorems_ndcg@10 (0.0265), Performs well on bright_theoremqa_theorems_recall@100 (0.1382), Performs well on bright_theoremqa_theorems_index_time_ms (10596.0036), Performs well on bright_theoremqa_theorems_query_time_ms (922.4393), Performs well on beir_scidocs_ndcg@10 (0.1462), Performs well on beir_scidocs_recall@100 (0.3437), Performs well on beir_scidocs_index_time_ms (19430.0675), Performs well on beir_scidocs_query_time_ms (3447.2729), Performs well on bright_economics_ndcg@10 (0.1648), Performs well on bright_economics_recall@100 (0.3891), Performs well on bright_economics_index_time_ms (13972.7823), Performs well on bright_economics_query_time_ms (2544.5837), Performs well on bright_biology_ndcg@10 (0.2426), Performs well on bright_biology_recall@100 (0.4889), Performs well on bright_biology_index_time_ms (14827.4495), Performs well on bright_biology_query_time_ms (2468.2880), Performs well on beir_fiqa_ndcg@10 (0.2258), Performs well on beir_fiqa_recall@100 (0.5279), Performs well on beir_fiqa_index_time_ms (32746.0572), Performs well on beir_fiqa_query_time_ms (6245.7120), Performs well on bright_earth_science_ndcg@10 (0.3585), Performs well on bright_earth_science_recall@100 (0.6521), Performs well on bright_earth_science_index_time_ms (30934.4683), Performs well on bright_earth_science_query_time_ms (3988.7256), Performs well on bright_stackoverflow_ndcg@10 (0.1829), Performs well on bright_stackoverflow_recall@100 (0.4559), Performs well on bright_stackoverflow_index_time_ms (97168.8703), Performs well on bright_stackoverflow_query_time_ms (9139.0520), Performs well on beir_trec-covid_ndcg@10 (0.6603), Performs well on beir_trec-covid_recall@100 (0.1062), Performs well on beir_trec-covid_index_time_ms (132465.0778), Performs well on beir_trec-covid_query_time_ms (1429.0537), Performs well on avg_ndcg@10 (0.2820), Performs well on avg_recall@100 (0.4566), Performs well on combined_score (0.4217), Performs well on total_index_time_ms (367366.8804), Performs well on total_query_time_ms (52559.6624), Performs well on total_time_ms (419926.5428), Performs well on datasets_evaluated (12.0000), Performs well on datasets_failed (0.0000), Performs well on error (0.0000)\n\n### Program 2 (Score: 0.4213)\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n    alpha: float = 1.0\n    beta: float = 1.0\n\n    # Light document-level priors\n    gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    # New: informativeness gate (bounded, smooth) to reduce ultra-rare spikes + ignore near-stopword terms\n    info_pivot: float = 2.0   # pivot in balanced-idf space\n    info_strength: float = 0.45  # how much the gate can amplify informative terms\n    info_floor: float = 0.70  # minimum multiplier (prevents killing recall)\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def informativeness_gate(idf_bal: float, pivot: float, strength: float, floor: float) -> float:\n        \"\"\"\n        New primitive: bounded informativeness multiplier in [floor, floor+strength].\n        Uses balanced-idf (less spiky than lucene idf) and tanh compression.\n        - Very common terms => ~floor\n        - Moderately informative => rises smoothly\n        - Ultra-rare => saturates (prevents domination)\n        \"\"\"\n        f = max(0.0, min(1.0, floor))\n        s = max(0.0, strength)\n        x = (idf_bal - pivot) / (pivot + EvolvedParameters.epsilon)\n        return f + s * (0.5 + 0.5 * math.tanh(x))\n\n    @staticmethod\n    def informativeness_gate_vectorized(\n        idf_bal: NDArray[np.float64], pivot: float, strength: float, floor: float\n    ) -> NDArray[np.float64]:\n        f = float(max(0.0, min(1.0, floor)))\n        s = float(max(0.0, strength))\n        x = (idf_bal - pivot) / (pivot + EvolvedParameters.epsilon)\n        return f + s * (0.5 + 0.5 * np.tanh(x))\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded rarity for coordination/priors: log1p((1-p)/p) where p=df/N.\n        Helps avoid ultra-rare terms fully dominating rarity-mass coverage.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        # 1 + strength * pivot/(pivot+idf)\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float\n    ) -> float:\n        \"\"\"\n        New primitive: coordination based on rarity-mass coverage instead of term-count coverage.\n        Intuition: matching rare query terms should matter more than matching generic ones.\n        Returns (matched_rarity/total_rarity)^beta with smoothing.\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        m = max(0.0, matched_rarity)\n        return (m / t) ** max(0.0, beta)\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        return coverage * coverage\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n        # Use balanced idf only as a *gate driver* (bounded), not as the main magnitude.\n        idf_bal = ScoringPrimitives.idf_balanced(df, N)\n        info = ScoringPrimitives.informativeness_gate(\n            idf_bal,\n            EvolvedParameters.info_pivot,\n            EvolvedParameters.info_strength,\n            EvolvedParameters.info_floor,\n        )\n\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n        tf_comp = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue * info\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong.\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # New: rarity-aware coordination multiplier improves early precision (nDCG@10)\n        # while being less harsh than count-based coordination on long/noisy queries.\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity, total_rarity, EvolvedParameters.coord_beta\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        # Deduplicate terms and use saturated qtf weighting (classic BM25 query term factor idea)\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    return DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        for i, term_id in enumerate(query_term_ids):\n            idf = self.corpus.idf_array[term_id]\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            # Informativeness gate (bounded), driven by balanced-idf.\n            df_t = float(self.corpus._df[term_id])\n            idf_bal = ScoringPrimitives.idf_balanced(df_t, self.corpus.N)\n            info = ScoringPrimitives.informativeness_gate(\n                idf_bal,\n                EvolvedParameters.info_pivot,\n                EvolvedParameters.info_strength,\n                EvolvedParameters.info_floor,\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            matched += (tf_row > 0).astype(np.float64)\n\n            tf_saturated = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            scores += weight * idf * rescue * info * tf_saturated\n\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n        if EvolvedParameters.coord_beta > 0 and qn > 0:\n            # balanced rarity per query term (bounded)\n            df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n            rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n            rarity_q = np.maximum(rarity_q, 0.0)\n            total_rarity = float(np.sum(rarity_q))\n            if total_rarity > 0:\n                # matched_rarity: sum rarity of query terms present in doc\n                matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                for i, term_id in enumerate(query_term_ids):\n                    tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                    matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n\n                scores *= np.power(\n                    np.maximum(matched_rarity / total_rarity, 0.0),\n                    EvolvedParameters.coord_beta,\n                )\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        # Keep rank() consistent with QueryProcessor: dedup + saturated qtf\n        term_counts = Counter(query)\n        query_term_ids: list[int] = []\n        query_term_weights: list[float] = []\n        for term, count in term_counts.items():\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(\n                    ScoringPrimitives.query_weight_saturated(float(count), EvolvedParameters.k3)\n                )\n\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\nKey features: Performs well on beir_nfcorpus_ndcg@10 (0.3135), Performs well on beir_nfcorpus_recall@100 (0.2544), Performs well on beir_nfcorpus_index_time_ms (3492.8307), Performs well on beir_nfcorpus_query_time_ms (136.7948), Performs well on beir_scifact_ndcg@10 (0.6766), Performs well on beir_scifact_recall@100 (0.9280), Performs well on beir_scifact_index_time_ms (4717.7408), Performs well on beir_scifact_query_time_ms (524.0140), Performs well on bright_pony_ndcg@10 (0.1374), Performs well on bright_pony_recall@100 (0.3362), Performs well on bright_pony_index_time_ms (1439.5825), Performs well on bright_pony_query_time_ms (698.9180), Performs well on beir_arguana_ndcg@10 (0.2675), Performs well on beir_arguana_recall@100 (0.8922), Performs well on beir_arguana_index_time_ms (5718.9641), Performs well on beir_arguana_query_time_ms (30917.3652), Performs well on bright_theoremqa_theorems_ndcg@10 (0.0348), Performs well on bright_theoremqa_theorems_recall@100 (0.1404), Performs well on bright_theoremqa_theorems_index_time_ms (10378.8810), Performs well on bright_theoremqa_theorems_query_time_ms (1252.0383), Performs well on beir_scidocs_ndcg@10 (0.1440), Performs well on beir_scidocs_recall@100 (0.3360), Performs well on beir_scidocs_index_time_ms (19044.9004), Performs well on beir_scidocs_query_time_ms (4236.1484), Performs well on bright_economics_ndcg@10 (0.1350), Performs well on bright_economics_recall@100 (0.3587), Performs well on bright_economics_index_time_ms (13514.0485), Performs well on bright_economics_query_time_ms (3510.8285), Performs well on bright_biology_ndcg@10 (0.2629), Performs well on bright_biology_recall@100 (0.5298), Performs well on bright_biology_index_time_ms (14682.6185), Performs well on bright_biology_query_time_ms (3360.5938), Performs well on beir_fiqa_ndcg@10 (0.2239), Performs well on beir_fiqa_recall@100 (0.5213), Performs well on beir_fiqa_index_time_ms (32486.5020), Performs well on beir_fiqa_query_time_ms (7111.0440), Performs well on bright_earth_science_ndcg@10 (0.3321), Performs well on bright_earth_science_recall@100 (0.6504), Performs well on bright_earth_science_index_time_ms (30947.4680), Performs well on bright_earth_science_query_time_ms (5672.8213), Performs well on bright_stackoverflow_ndcg@10 (0.1724), Performs well on bright_stackoverflow_recall@100 (0.4415), Performs well on bright_stackoverflow_index_time_ms (98303.4775), Performs well on bright_stackoverflow_query_time_ms (12566.7329), Performs well on beir_trec-covid_ndcg@10 (0.6144), Performs well on beir_trec-covid_recall@100 (0.1016), Performs well on beir_trec-covid_index_time_ms (131536.9812), Performs well on beir_trec-covid_query_time_ms (1731.7452), Performs well on avg_ndcg@10 (0.2762), Performs well on avg_recall@100 (0.4575), Performs well on combined_score (0.4213), Performs well on total_index_time_ms (366263.9954), Performs well on total_query_time_ms (71719.0444), Performs well on total_time_ms (437983.0398), Performs well on datasets_evaluated (12.0000), Performs well on datasets_failed (0.0000), Performs well on error (0.0000)\n\n### Program 3 (Score: 0.4206)\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n\n    # Light document-level priors\n    gamma: float = 0.20  # slight trim; early-hit bonus will add back targeted ranking signal\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # Rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    # New: early-hit proximity surrogate (cheap, no positional index)\n    early_strength: float = 0.10\n    early_window: int = 64        # consider only first W tokens for \"early\" evidence\n    early_cover_beta: float = 1.3 # gate by coverage^beta so 1-term matches don't get over-boosted\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def early_hit_bonus(min_pos: int | None, window: int) -> float:\n        \"\"\"\n        New primitive: cheap proximity/field surrogate from *first occurrence position*.\n        - If a query term appears early, it is often a title/abstract-like signal.\n        - window limits the effect to early tokens; outside window => 0.\n        Returns in [0,1]: 1/(1+pos) if pos in [0, window), else 0.\n        \"\"\"\n        if min_pos is None or min_pos < 0 or min_pos >= window:\n            return 0.0\n        return 1.0 / (1.0 + float(min_pos))\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded rarity for coordination/priors: log1p((1-p)/p) where p=df/N.\n        Helps avoid ultra-rare terms fully dominating rarity-mass coverage.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        # 1 + strength * pivot/(pivot+idf)\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float\n    ) -> float:\n        \"\"\"\n        New primitive: coordination based on rarity-mass coverage instead of term-count coverage.\n        Intuition: matching rare query terms should matter more than matching generic ones.\n        Returns (matched_rarity/total_rarity)^beta with smoothing.\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        m = max(0.0, matched_rarity)\n        return (m / t) ** max(0.0, beta)\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        return coverage * coverage\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n        tf_comp = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong.\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # New: rarity-aware coordination multiplier improves early precision (nDCG@10)\n        # while being less harsh than count-based coordination on long/noisy queries.\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity, total_rarity, EvolvedParameters.coord_beta\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        # Deduplicate terms and use saturated qtf weighting (classic BM25 query term factor idea)\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # New: early-hit doc prior (computed from token stream; no positional index needed)\n    early_sum = 0.0\n    early_wsum = 0.0\n    if EvolvedParameters.early_strength > 0:\n        tokens = corpus.documents[doc_idx]\n        window = max(1, int(EvolvedParameters.early_window))\n        # Build first-position map for only the early window for speed\n        first_pos: dict[str, int] = {}\n        for i, t in enumerate(tokens[:window]):\n            if t not in first_pos:\n                first_pos[t] = i\n\n    # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n            if EvolvedParameters.early_strength > 0:\n                b = ScoringPrimitives.early_hit_bonus(first_pos.get(term), window)\n                early_sum += float(w) * b\n                early_wsum += float(w)\n\n    base = DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n    # Add early-hit prior gated by coverage (helps nDCG@10; usually safe for recall@100)\n    if EvolvedParameters.early_strength > 0 and early_wsum > 0 and len(query_terms) > 0:\n        coverage = matched_count / float(len(query_terms))\n        gate = coverage ** max(0.0, EvolvedParameters.early_cover_beta)\n        base += EvolvedParameters.early_strength * (early_sum / early_wsum) * gate\n\n    return base\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        for i, term_id in enumerate(query_term_ids):\n            idf = self.corpus.idf_array[term_id]\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            matched += (tf_row > 0).astype(np.float64)\n\n            tf_saturated = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            scores += weight * idf * rescue * tf_saturated\n\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n        if EvolvedParameters.coord_beta > 0 and qn > 0:\n            # balanced rarity per query term (bounded)\n            df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n            rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n            rarity_q = np.maximum(rarity_q, 0.0)\n            total_rarity = float(np.sum(rarity_q))\n            if total_rarity > 0:\n                # matched_rarity: sum rarity of query terms present in doc\n                matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                for i, term_id in enumerate(query_term_ids):\n                    tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                    matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n\n                scores *= np.power(\n                    np.maximum(matched_rarity / total_rarity, 0.0),\n                    EvolvedParameters.coord_beta,\n                )\n\n        # Early-hit bonus (post-hoc; keeps consistent with score_kernel)\n        if EvolvedParameters.early_strength > 0 and qn > 0:\n            window = max(1, int(EvolvedParameters.early_window))\n            qweights = query_term_weights if query_term_weights is not None else np.ones(len(query_term_ids), dtype=np.float64)\n\n            # coverage gate from already computed matched\n            coverage = matched / qn\n            gate = np.power(coverage, max(0.0, float(EvolvedParameters.early_cover_beta)))\n\n            early = np.zeros(len(candidate_docs), dtype=np.float64)\n            wsum = float(np.sum(qweights)) + EvolvedParameters.epsilon\n\n            # For each candidate doc, scan first window tokens and accumulate weighted early hits\n            for j, doc_idx in enumerate(candidate_docs.tolist()):\n                first_pos: dict[int, int] = {}\n                for pos, tok in enumerate(self.corpus.documents[doc_idx][:window]):\n                    tid = self.corpus.get_term_id(tok)\n                    if tid is not None and tid not in first_pos:\n                        first_pos[tid] = pos\n                s = 0.0\n                for term_id, w in zip(query_term_ids, qweights, strict=False):\n                    p = first_pos.get(term_id)\n                    if p is not None:\n                        s += float(w) * (1.0 / (1.0 + float(p)))\n                early[j] = s / wsum\n\n            scores += float(EvolvedParameters.early_strength) * early * gate\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        # Keep rank() consistent with QueryProcessor: dedup + saturated qtf\n        term_counts = Counter(query)\n        query_term_ids: list[int] = []\n        query_term_weights: list[float] = []\n        for term, count in term_counts.items():\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(\n                    ScoringPrimitives.query_weight_saturated(float(count), EvolvedParameters.k3)\n                )\n\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\nKey features: Performs well on beir_nfcorpus_ndcg@10 (0.3136), Performs well on beir_nfcorpus_recall@100 (0.2526), Performs well on beir_nfcorpus_index_time_ms (3485.4698), Performs well on beir_nfcorpus_query_time_ms (1911.5743), Performs well on bright_pony_ndcg@10 (0.1357), Performs well on bright_pony_recall@100 (0.3358), Performs well on bright_pony_index_time_ms (1490.9817), Performs well on bright_pony_query_time_ms (4952.1225), Performs well on beir_scifact_ndcg@10 (0.6757), Performs well on beir_scifact_recall@100 (0.9247), Performs well on beir_scifact_index_time_ms (4806.7429), Performs well on beir_scifact_query_time_ms (8728.8354), Performs well on beir_arguana_ndcg@10 (0.2586), Performs well on beir_arguana_recall@100 (0.8772), Performs well on beir_arguana_index_time_ms (5875.8071), Performs well on beir_arguana_query_time_ms (188053.1643), Performs well on bright_theoremqa_theorems_ndcg@10 (0.0328), Performs well on bright_theoremqa_theorems_recall@100 (0.1469), Performs well on bright_theoremqa_theorems_index_time_ms (10487.0187), Performs well on bright_theoremqa_theorems_query_time_ms (12658.7517), Performs well on beir_scidocs_ndcg@10 (0.1420), Performs well on beir_scidocs_recall@100 (0.3352), Performs well on beir_scidocs_index_time_ms (19629.8387), Performs well on beir_scidocs_query_time_ms (106867.2750), Performs well on bright_economics_ndcg@10 (0.1331), Performs well on bright_economics_recall@100 (0.3680), Performs well on bright_economics_index_time_ms (13926.8271), Performs well on bright_economics_query_time_ms (24660.5844), Performs well on bright_biology_ndcg@10 (0.2583), Performs well on bright_biology_recall@100 (0.5387), Performs well on bright_biology_index_time_ms (14499.6342), Performs well on bright_biology_query_time_ms (31339.5724), Performs well on bright_earth_science_ndcg@10 (0.3281), Performs well on bright_earth_science_recall@100 (0.6466), Performs well on bright_earth_science_index_time_ms (31667.2844), Performs well on bright_earth_science_query_time_ms (53723.1652), Performs well on beir_trec-covid_ndcg@10 (0.6247), Performs well on beir_trec-covid_recall@100 (0.1009), Performs well on beir_trec-covid_index_time_ms (137169.2561), Performs well on beir_trec-covid_query_time_ms (45983.5261), Performs well on bright_stackoverflow_ndcg@10 (0.1740), Performs well on bright_stackoverflow_recall@100 (0.4371), Performs well on bright_stackoverflow_index_time_ms (99682.7822), Performs well on bright_stackoverflow_query_time_ms (93263.4285), Performs well on beir_fiqa_ndcg@10 (0.2216), Performs well on beir_fiqa_recall@100 (0.5206), Performs well on beir_fiqa_index_time_ms (33879.9398), Performs well on beir_fiqa_query_time_ms (181470.2380), Performs well on avg_ndcg@10 (0.2748), Performs well on avg_recall@100 (0.4570), Performs well on combined_score (0.4206), Performs well on total_index_time_ms (376601.5827), Performs well on total_query_time_ms (753612.2378), Performs well on total_time_ms (1130213.8205), Performs well on datasets_evaluated (12.0000), Performs well on datasets_failed (0.0000), Performs well on error (0.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.4206)\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n    alpha: float = 1.0\n    beta: float = 1.0\n\n    # Light document-level priors\n    gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded rarity for coordination/priors: log1p((1-p)/p) where p=df/N.\n        Helps avoid ultra-rare terms fully dominating rarity-mass coverage.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        # 1 + strength * pivot/(pivot+idf)\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float\n    ) -> float:\n        \"\"\"\n        New primitive: coordination based on rarity-mass coverage instead of term-count coverage.\n        Intuition: matching rare query terms should matter more than matching generic ones.\n        Returns (matched_rarity/total_rarity)^beta with smoothing.\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        m = max(0.0, matched_rarity)\n        return (m / t) ** max(0.0, beta)\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        return coverage * coverage\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n        tf_comp = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong.\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # New: rarity-aware coordination multiplier improves early precision (nDCG@10)\n        # while being less harsh than count-based coordination on long/noisy queries.\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity, total_rarity, EvolvedParameters.coord_beta\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        # Deduplicate terms and use saturated qtf weighting (classic BM25 query term factor idea)\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    return DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        for i, term_id in enumerate(query_term_ids):\n            idf = self.corpus.idf_array[term_id]\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            matched += (tf_row > 0).astype(np.float64)\n\n            tf_saturated = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            scores += weight * idf * rescue * tf_saturated\n\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n        if EvolvedParameters.coord_beta > 0 and qn > 0:\n            # balanced rarity per query term (bounded)\n            df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n            rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n            rarity_q = np.maximum(rarity_q, 0.0)\n            total_rarity = float(np.sum(rarity_q))\n            if total_rarity > 0:\n                # matched_rarity: sum rarity of query terms present in doc\n                matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                for i, term_id in enumerate(query_term_ids):\n                    tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                    matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n\n                scores *= np.power(\n                    np.maximum(matched_rarity / total_rarity, 0.0),\n                    EvolvedParameters.coord_beta,\n                )\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        # Keep rank() consistent with QueryProcessor: dedup + saturated qtf\n        term_counts = Counter(query)\n        query_term_ids: list[int] = []\n        query_term_weights: list[float] = []\n        for term, count in term_counts.items():\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(\n                    ScoringPrimitives.query_weight_saturated(float(count), EvolvedParameters.k3)\n                )\n\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\nKey features: Alternative approach to beir_nfcorpus_ndcg@10, Alternative approach to beir_nfcorpus_recall@100\n\n### Program D2 (Score: 0.4181)\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n    alpha: float = 1.0\n    beta: float = 1.0\n\n    # Light document-level priors\n    gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    # New: burstiness-aware TF compression (helps noisy/repetitive docs; preserves 1-hit signal)\n    tf_log_mix: float = 0.35  # 0 => pure lucene saturation, 1 => pure log-TF saturation\n    tf_log_k: float = 1.0     # higher => weaker log compression\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def saturate_logtf_lucene(tf: float, k1: float, norm: float, k: float) -> float:\n        \"\"\"\n        New primitive: log-compressed TF then Lucene saturation.\n        This reduces dominance of bursty terms (common in long docs / code dumps)\n        while keeping tf=1 close to standard behavior.\n        \"\"\"\n        if tf <= 0:\n            return 0.0\n        kk = max(k, EvolvedParameters.epsilon)\n        t = math.log1p(tf / kk)\n        denom = t + k1 * norm + EvolvedParameters.epsilon\n        return t / denom\n\n    @staticmethod\n    def saturate_logtf_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64], k: float\n    ) -> NDArray[np.float64]:\n        kk = float(max(k, EvolvedParameters.epsilon))\n        t = np.log1p(tf / kk)\n        denom = t + k1 * norm + EvolvedParameters.epsilon\n        return t / denom\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded rarity for coordination/priors: log1p((1-p)/p) where p=df/N.\n        Helps avoid ultra-rare terms fully dominating rarity-mass coverage.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        # 1 + strength * pivot/(pivot+idf)\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float\n    ) -> float:\n        \"\"\"\n        New primitive: coordination based on rarity-mass coverage instead of term-count coverage.\n        Intuition: matching rare query terms should matter more than matching generic ones.\n        Returns (matched_rarity/total_rarity)^beta with smoothing.\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        m = max(0.0, matched_rarity)\n        return (m / t) ** max(0.0, beta)\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        return coverage * coverage\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n\n        mix = max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix)))\n        tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n        tf_logsat = ScoringPrimitives.saturate_logtf_lucene(\n            tf, k1, norm, EvolvedParameters.tf_log_k\n        )\n        tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong.\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # New: rarity-aware coordination multiplier improves early precision (nDCG@10)\n        # while being less harsh than count-based coordination on long/noisy queries.\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity, total_rarity, EvolvedParameters.coord_beta\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        # Deduplicate terms and use saturated qtf weighting (classic BM25 query term factor idea)\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    return DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n        for i, term_id in enumerate(query_term_ids):\n            idf = self.corpus.idf_array[term_id]\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            matched += (tf_row > 0).astype(np.float64)\n\n            tf_sat = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            tf_logsat = ScoringPrimitives.saturate_logtf_lucene_vectorized(\n                tf_row, k1, norms, EvolvedParameters.tf_log_k\n            )\n            tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n            scores += weight * idf * rescue * tf_comp\n\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n        if EvolvedParameters.coord_beta > 0 and qn > 0:\n            # balanced rarity per query term (bounded)\n            df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n            rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n            rarity_q = np.maximum(rarity_q, 0.0)\n            total_rarity = float(np.sum(rarity_q))\n            if total_rarity > 0:\n                # matched_rarity: sum rarity of query terms present in doc\n                matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                for i, term_id in enumerate(query_term_ids):\n                    tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                    matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n\n                scores *= np.power(\n                    np.maximum(matched_rarity / total_rarity, 0.0),\n                    EvolvedParameters.coord_beta,\n                )\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        # Keep rank() consistent with QueryProcessor: dedup + saturated qtf\n        term_counts = Counter(query)\n        query_term_ids: list[int] = []\n        query_term_weights: list[float] = []\n        for term, count in term_counts.items():\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(\n                    ScoringPrimitives.query_weight_saturated(float(count), EvolvedParameters.k3)\n                )\n\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\nKey features: Alternative approach to beir_nfcorpus_ndcg@10, Alternative approach to beir_nfcorpus_recall@100\n\n### Program D3 (Score: 0.4205)\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n\n    # Light document-level priors\n    gamma: float = 0.20  # slight trim; early-hit bonus will add back targeted ranking signal\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # Rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    # Early-region priors (precomputed per doc; avoids per-query token scanning)\n    early_strength: float = 0.06\n    early_window: int = 64\n    early_cover_beta: float = 1.3\n\n    # New: distinctiveness prior in early window (cheap \u201ctitle/abstract density\u201d proxy)\n    early_distinct_strength: float = 0.08\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def early_hit_bonus(min_pos: int | None, window: int) -> float:\n        \"\"\"\n        New primitive: cheap proximity/field surrogate from *first occurrence position*.\n        - If a query term appears early, it is often a title/abstract-like signal.\n        - window limits the effect to early tokens; outside window => 0.\n        Returns in [0,1]: 1/(1+pos) if pos in [0, window), else 0.\n        \"\"\"\n        if min_pos is None or min_pos < 0 or min_pos >= window:\n            return 0.0\n        return 1.0 / (1.0 + float(min_pos))\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded rarity for coordination/priors: log1p((1-p)/p) where p=df/N.\n        Helps avoid ultra-rare terms fully dominating rarity-mass coverage.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        # 1 + strength * pivot/(pivot+idf)\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float\n    ) -> float:\n        \"\"\"\n        New primitive: coordination based on rarity-mass coverage instead of term-count coverage.\n        Intuition: matching rare query terms should matter more than matching generic ones.\n        Returns (matched_rarity/total_rarity)^beta with smoothing.\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        m = max(0.0, matched_rarity)\n        return (m / t) ** max(0.0, beta)\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        return coverage * coverage\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n        tf_comp = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong.\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # New: rarity-aware coordination multiplier improves early precision (nDCG@10)\n        # while being less harsh than count-based coordination on long/noisy queries.\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity, total_rarity, EvolvedParameters.coord_beta\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        # Deduplicate terms and use saturated qtf weighting (classic BM25 query term factor idea)\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # Early priors are precomputed in Corpus for speed/consistency with vectorized ranking.\n\n    # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n            # no-op: early prior handled after scoring via precomputed corpus.early_distinct_array\n\n    base = DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n    # Add early distinctiveness prior gated by coverage (cheap; consistent with vectorized path).\n    if EvolvedParameters.early_distinct_strength > 0 and len(query_terms) > 0:\n        coverage = matched_count / float(len(query_terms))\n        gate = coverage ** max(0.0, EvolvedParameters.early_cover_beta)\n        base += float(EvolvedParameters.early_distinct_strength) * float(\n            corpus.early_distinct_array[doc_idx]\n        ) * gate\n\n    return base\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n\n        # Precompute early-window distinctiveness prior:\n        # distinct_ratio = unique_tokens_in_first_W / W  in [0,1]\n        # Fast at query time and correlates with \u201cdense title/abstract\u201d style text.\n        W = max(1, int(EvolvedParameters.early_window))\n        early_distinct = np.zeros(self.N, dtype=np.float64)\n        for i, doc in enumerate(documents):\n            w = doc[:W]\n            if w:\n                early_distinct[i] = min(1.0, float(len(set(w))) / float(len(w)))\n        self.early_distinct_array = early_distinct\n\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        for i, term_id in enumerate(query_term_ids):\n            idf = self.corpus.idf_array[term_id]\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            matched += (tf_row > 0).astype(np.float64)\n\n            tf_saturated = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            scores += weight * idf * rescue * tf_saturated\n\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n        if EvolvedParameters.coord_beta > 0 and qn > 0:\n            # balanced rarity per query term (bounded)\n            df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n            rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n            rarity_q = np.maximum(rarity_q, 0.0)\n            total_rarity = float(np.sum(rarity_q))\n            if total_rarity > 0:\n                # matched_rarity: sum rarity of query terms present in doc\n                matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                for i, term_id in enumerate(query_term_ids):\n                    tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                    matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n\n                scores *= np.power(\n                    np.maximum(matched_rarity / total_rarity, 0.0),\n                    EvolvedParameters.coord_beta,\n                )\n\n        # Cheap early-window priors (no per-query document token scanning).\n        if qn > 0:\n            coverage = matched / qn\n            gate = np.power(coverage, max(0.0, float(EvolvedParameters.early_cover_beta)))\n\n            if EvolvedParameters.early_distinct_strength > 0:\n                scores += float(EvolvedParameters.early_distinct_strength) * (\n                    self.corpus.early_distinct_array[candidate_docs]\n                ) * gate\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        # Keep rank() consistent with QueryProcessor: dedup + saturated qtf\n        term_counts = Counter(query)\n        query_term_ids: list[int] = []\n        query_term_weights: list[float] = []\n        for term, count in term_counts.items():\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(\n                    ScoringPrimitives.query_weight_saturated(float(count), EvolvedParameters.k3)\n                )\n\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\nKey features: Alternative approach to beir_nfcorpus_ndcg@10, Alternative approach to beir_nfcorpus_recall@100\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.4206, Type: Migrant)\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n    alpha: float = 1.0\n    beta: float = 1.0\n\n    # Light document-level priors\n    gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded rarity for coordination/priors: log1p((1-p)/p) where p=df/N.\n        Helps avoid ultra-rare terms fully dominating rarity-mass coverage.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        # 1 + strength * pivot/(pivot+idf)\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float\n    ) -> float:\n        \"\"\"\n        New primitive: coordination based on rarity-mass coverage instead of term-count coverage.\n        Intuition: matching rare query terms should matter more than matching generic ones.\n        Returns (matched_rarity/total_rarity)^beta with smoothing.\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        m = max(0.0, matched_rarity)\n        return (m / t) ** max(0.0, beta)\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        return coverage * coverage\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n        tf_comp = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong.\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # New: rarity-aware coordination multiplier improves early precision (nDCG@10)\n        # while being less harsh than count-based coordination on long/noisy queries.\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity, total_rarity, EvolvedParameters.coord_beta\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        # Deduplicate terms and use saturated qtf weighting (classic BM25 query term factor idea)\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    return DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        for i, term_id in enumerate(query_term_ids):\n            idf = self.corpus.idf_array[term_id]\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            matched += (tf_row > 0).astype(np.float64)\n\n            tf_saturated = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            scores += weight * idf * rescue * tf_saturated\n\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n        if EvolvedParameters.coord_beta > 0 and qn > 0:\n            # balanced rarity per query term (bounded)\n            df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n            rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n            rarity_q = np.maximum(rarity_q, 0.0)\n            total_rarity = float(np.sum(rarity_q))\n            if total_rarity > 0:\n                # matched_rarity: sum rarity of query terms present in doc\n                matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                for i, term_id in enumerate(query_term_ids):\n                    tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                    matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n\n                scores *= np.power(\n                    np.maximum(matched_rarity / total_rarity, 0.0),\n                    EvolvedParameters.coord_beta,\n                )\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        # Keep rank() consistent with QueryProcessor: dedup + saturated qtf\n        term_counts = Counter(query)\n        query_term_ids: list[int] = []\n        query_term_weights: list[float] = []\n        for term, count in term_counts.items():\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(\n                    ScoringPrimitives.query_weight_saturated(float(count), EvolvedParameters.k3)\n                )\n\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.4205, Type: Experimental)\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n\n    # Light document-level priors\n    gamma: float = 0.20  # slight trim; early-hit bonus will add back targeted ranking signal\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # Rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    # Early-region priors (precomputed per doc; avoids per-query token scanning)\n    early_strength: float = 0.06\n    early_window: int = 64\n    early_cover_beta: float = 1.3\n\n    # New: distinctiveness prior in early window (cheap \u201ctitle/abstract density\u201d proxy)\n    early_distinct_strength: float = 0.08\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def early_hit_bonus(min_pos: int | None, window: int) -> float:\n        \"\"\"\n        New primitive: cheap proximity/field surrogate from *first occurrence position*.\n        - If a query term appears early, it is often a title/abstract-like signal.\n        - window limits the effect to early tokens; outside window => 0.\n        Returns in [0,1]: 1/(1+pos) if pos in [0, window), else 0.\n        \"\"\"\n        if min_pos is None or min_pos < 0 or min_pos >= window:\n            return 0.0\n        return 1.0 / (1.0 + float(min_pos))\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded rarity for coordination/priors: log1p((1-p)/p) where p=df/N.\n        Helps avoid ultra-rare terms fully dominating rarity-mass coverage.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        # 1 + strength * pivot/(pivot+idf)\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float\n    ) -> float:\n        \"\"\"\n        New primitive: coordination based on rarity-mass coverage instead of term-count coverage.\n        Intuition: matching rare query terms should matter more than matching generic ones.\n        Returns (matched_rarity/total_rarity)^beta with smoothing.\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        m = max(0.0, matched_rarity)\n        return (m / t) ** max(0.0, beta)\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        return coverage * coverage\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n        tf_comp = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong.\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # New: rarity-aware coordination multiplier improves early precision (nDCG@10)\n        # while being less harsh than count-based coordination on long/noisy queries.\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity, total_rarity, EvolvedParameters.coord_beta\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        # Deduplicate terms and use saturated qtf weighting (classic BM25 query term factor idea)\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # Early priors are precomputed in Corpus for speed/consistency with vectorized ranking.\n\n    # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n            # no-op: early prior handled after scoring via precomputed corpus.early_distinct_array\n\n    base = DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n    # Add early distinctiveness prior gated by coverage (cheap; consistent with vectorized path).\n    if EvolvedParameters.early_distinct_strength > 0 and len(query_terms) > 0:\n        coverage = matched_count / float(len(query_terms))\n        gate = coverage ** max(0.0, EvolvedParameters.early_cover_beta)\n        base += float(EvolvedParameters.early_distinct_strength) * float(\n            corpus.early_distinct_array[doc_idx]\n        ) * gate\n\n    return base\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n\n        # Precompute early-window distinctiveness prior:\n        # distinct_ratio = unique_tokens_in_first_W / W  in [0,1]\n        # Fast at query time and correlates with \u201cdense title/abstract\u201d style text.\n        W = max(1, int(EvolvedParameters.early_window))\n        early_distinct = np.zeros(self.N, dtype=np.float64)\n        for i, doc in enumerate(documents):\n            w = doc[:W]\n            if w:\n                early_distinct[i] = min(1.0, float(len(set(w))) / float(len(w)))\n        self.early_distinct_array = early_distinct\n\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        for i, term_id in enumerate(query_term_ids):\n            idf = self.corpus.idf_array[term_id]\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            matched += (tf_row > 0).astype(np.float64)\n\n            tf_saturated = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            scores += weight * idf * rescue * tf_saturated\n\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n        if EvolvedParameters.coord_beta > 0 and qn > 0:\n            # balanced rarity per query term (bounded)\n            df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n            rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n            rarity_q = np.maximum(rarity_q, 0.0)\n            total_rarity = float(np.sum(rarity_q))\n            if total_rarity > 0:\n                # matched_rarity: sum rarity of query terms present in doc\n                matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                for i, term_id in enumerate(query_term_ids):\n                    tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                    matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n\n                scores *= np.power(\n                    np.maximum(matched_rarity / total_rarity, 0.0),\n                    EvolvedParameters.coord_beta,\n                )\n\n        # Cheap early-window priors (no per-query document token scanning).\n        if qn > 0:\n            coverage = matched / qn\n            gate = np.power(coverage, max(0.0, float(EvolvedParameters.early_cover_beta)))\n\n            if EvolvedParameters.early_distinct_strength > 0:\n                scores += float(EvolvedParameters.early_distinct_strength) * (\n                    self.corpus.early_distinct_array[candidate_docs]\n                ) * gate\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        # Keep rank() consistent with QueryProcessor: dedup + saturated qtf\n        term_counts = Counter(query)\n        query_term_ids: list[int] = []\n        query_term_weights: list[float] = []\n        for term, count in term_counts.items():\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(\n                    ScoringPrimitives.query_weight_saturated(float(count), EvolvedParameters.k3)\n                )\n\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.4217, Type: Migrant)\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n\n    # TF blending (keep; tends to help long/noisy docs)\n    alpha: float = 0.6\n\n    # Additive recall-friendly coverage bonus (helps recall@100 without harsh AND)\n    gamma: float = 0.22\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # Rarity-aware coordination (soft AND), bounded to protect recall\n    coord_beta: float = 0.55\n    coord_floor: float = 0.35\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        c = matched_terms / total_query_terms\n        return c * c\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float, floor: float\n    ) -> float:\n        \"\"\"\n        Coordination based on rarity-mass coverage (soft AND), bounded for recall.\n        Returns: floor + (1-floor) * (matched_rarity/total_rarity)^beta\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        frac = max(0.0, matched_rarity) / t\n        f = max(0.0, min(1.0, floor))\n        return f + (1.0 - f) * (frac ** max(0.0, beta))\n\n    @staticmethod\n    def coord_rarity_aware_vectorized(\n        matched_rarity: NDArray[np.float64],\n        total_rarity: float,\n        beta: float,\n        floor: float,\n    ) -> NDArray[np.float64]:\n        t = max(float(total_rarity), EvolvedParameters.epsilon)\n        frac = np.maximum(matched_rarity, 0.0) / t\n        f = float(max(0.0, min(1.0, floor)))\n        return f + (1.0 - f) * np.power(frac, max(0.0, float(beta)))\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded, two-sided IDF: reduces ultra-rare spikes while still penalizing frequent terms.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def tf_salience(tf: float, dl: float, avgdl: float) -> float:\n        \"\"\"\n        Length-aware TF salience: downweights inflated TF in long docs.\n        \"\"\"\n        denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n        return tf / (denom + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def tf_salience_vectorized(\n        tf: NDArray[np.float64], dl: NDArray[np.float64], avgdl: float\n    ) -> NDArray[np.float64]:\n        denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n        return tf / (denom + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coord_factor(matched_terms: int, total_query_terms: int, beta: float) -> float:\n        \"\"\"\n        Soft coordination factor: (matched/total)^beta. Multiplies score.\n        \"\"\"\n        if total_query_terms <= 0 or matched_terms <= 0:\n            return 0.0\n        return (matched_terms / total_query_terms) ** max(beta, 0.0)\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def idf_mixed_compressed(df: float, N: int) -> float:\n        \"\"\"\n        New primitive: blend two IDFs then compress extremes.\n        Motivation: very rare terms can dominate nDCG@10; compression tends to improve\n        ranking robustness across heterogeneous BEIR/BRIGHT corpora while preserving recall.\n        \"\"\"\n        a = EvolvedParameters.alpha\n        idf_a = ScoringPrimitives.idf_lucene(df, N)\n        idf_b = ScoringPrimitives.idf_atire(df, N)\n        mixed = a * idf_a + (1.0 - a) * idf_b\n        # soft compression of very large idf values (keeps monotonicity)\n        p = EvolvedParameters.idf_pivot\n        beta = EvolvedParameters.beta\n        return mixed / (1.0 + beta * max(0.0, mixed - p))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_tflog_bm25(tf: float, k1: float, norm: float) -> float:\n        \"\"\"\n        New primitive: apply log-TF before BM25-style saturation.\n        Helps corpora with bursty term repetition (e.g., forum/stack traces) without\n        killing signals for single occurrences.\n        \"\"\"\n        if tf <= 0:\n            return 0.0\n        t = 1.0 + math.log(tf)\n        denom = t + k1 * norm + EvolvedParameters.epsilon\n        return (t * (k1 + 1.0)) / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        # more tunable than fixed square; tends to help nDCG@10 by preferring fuller matches\n        return coverage ** max(1.0, EvolvedParameters.cov_power)\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n\n        # Strong default IDF\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n\n        # TF: keep your blend (often helps for long docs / bursty tf)\n        tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n        tf_sal = ScoringPrimitives.tf_salience(tf, dl, avgdl)\n        tf_comp = (1.0 - EvolvedParameters.alpha) * tf_sat + EvolvedParameters.alpha * tf_sal\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # Bounded rarity-aware coordination improves early precision without killing recall\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity,\n                total_rarity,\n                EvolvedParameters.coord_beta,\n                EvolvedParameters.coord_floor,\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # rarity-mass coverage tracking (bounded rarity; reduces ultra-rare dominance)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    return DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        # Match TermScorer: lucene IDF array for fast vectorized scoring\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        dls = self.corpus.doc_lengths[candidate_docs]\n        avgdl = self.corpus.avgdl\n\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        # rarity-mass tracking\n        matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        total_rarity = 0.0\n\n        # Precompute bounded rarity per query term (balanced idf) for coordination\n        df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)] if query_term_ids else np.array([], dtype=np.float64)\n        rarity_q = (\n            ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N) if df_q.size else np.array([], dtype=np.float64)\n        )\n        rarity_q = np.maximum(rarity_q, 0.0)\n        total_rarity = float(np.sum(rarity_q)) if rarity_q.size else 0.0\n\n        for i, term_id in enumerate(query_term_ids):\n            idf = float(self.corpus.idf_array[term_id])\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            present = (tf_row > 0).astype(np.float64)\n            matched += present\n            if rarity_q.size:\n                matched_rarity += present * float(rarity_q[i])\n\n            tf_sat = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            tf_sal = ScoringPrimitives.tf_salience_vectorized(tf_row, dls, avgdl)\n            tf_comp = (1.0 - EvolvedParameters.alpha) * tf_sat + EvolvedParameters.alpha * tf_sal\n\n            scores += weight * idf * rescue * tf_comp\n\n        # Additive coverage bonus\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Bounded rarity-aware coordination\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            coord = ScoringPrimitives.coord_rarity_aware_vectorized(\n                matched_rarity,\n                total_rarity,\n                EvolvedParameters.coord_beta,\n                EvolvedParameters.coord_floor,\n            )\n            scores *= coord\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n        query_terms, query_weights = QueryProcessor.process(query)\n        query_term_ids = []\n        query_term_weights = []\n        for term, w in zip(query_terms, query_weights, strict=False):\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(float(w))\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n\"\"\"\nLexical retrieval as PRIMITIVES + STRUCTURE.\n- Primitives: atomic scoring pieces (IDF, TF, saturation, length norm, aggregation).\n- Structure: how they are combined (term score \u2192 doc score \u2192 ranking).\nThis seed is one structure (BM25-like); evolution can invent new primitives and new structure.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom collections import Counter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, lil_matrix\n\nfrom ranking_evolved.bm25 import (\n    ENGLISH_STOPWORDS,\n    LUCENE_STOPWORDS,\n    LuceneTokenizer as _BaseLuceneTokenizer,\n)\n\nif TYPE_CHECKING:\n    from numpy.typing import NDArray\n\nNUM_QUERY_WORKERS = 32\nMIN_QUERIES_FOR_PARALLEL = 10\n\n\n# ----- EVOLVE: Parameters -----\n\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n    alpha: float = 1.0\n    beta: float = 1.0\n\n    # Light document-level priors\n    gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    # New: burstiness-aware TF compression (helps noisy/repetitive docs; preserves 1-hit signal)\n    tf_log_mix: float = 0.35  # 0 => pure lucene saturation, 1 => pure log-TF saturation\n    tf_log_k: float = 1.0     # higher => weaker log compression\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n\n\n# ----- EVOLVE: Primitives (atoms). Add new ones or change formulas. -----\n\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def saturate_logtf_lucene(tf: float, k1: float, norm: float, k: float) -> float:\n        \"\"\"\n        New primitive: log-compressed TF then Lucene saturation.\n        This reduces dominance of bursty terms (common in long docs / code dumps)\n        while keeping tf=1 close to standard behavior.\n        \"\"\"\n        if tf <= 0:\n            return 0.0\n        kk = max(k, EvolvedParameters.epsilon)\n        t = math.log1p(tf / kk)\n        denom = t + k1 * norm + EvolvedParameters.epsilon\n        return t / denom\n\n    @staticmethod\n    def saturate_logtf_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64], k: float\n    ) -> NDArray[np.float64]:\n        kk = float(max(k, EvolvedParameters.epsilon))\n        t = np.log1p(tf / kk)\n        denom = t + k1 * norm + EvolvedParameters.epsilon\n        return t / denom\n\n    @staticmethod\n    def idf_balanced(df: float, N: int) -> float:\n        \"\"\"\n        Bounded rarity for coordination/priors: log1p((1-p)/p) where p=df/N.\n        Helps avoid ultra-rare terms fully dominating rarity-mass coverage.\n        \"\"\"\n        p = df / (N + EvolvedParameters.epsilon)\n        return math.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_balanced_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        p = df / (N + EvolvedParameters.epsilon)\n        return np.log1p((1.0 - p) / (p + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue(idf: float, strength: float, pivot: float) -> float:\n        \"\"\"\n        Boost frequent terms a bit (low idf), bounded and smooth.\n        When idf << pivot => multiplier ~ 1 + strength\n        When idf >> pivot => multiplier ~ 1\n        \"\"\"\n        # 1 + strength * pivot/(pivot+idf)\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def commonness_rescue_vectorized(\n        idf: NDArray[np.float64], strength: float, pivot: float\n    ) -> NDArray[np.float64]:\n        return 1.0 + strength * (pivot / (pivot + idf + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def coord_rarity_aware(\n        matched_rarity: float, total_rarity: float, beta: float\n    ) -> float:\n        \"\"\"\n        New primitive: coordination based on rarity-mass coverage instead of term-count coverage.\n        Intuition: matching rare query terms should matter more than matching generic ones.\n        Returns (matched_rarity/total_rarity)^beta with smoothing.\n        \"\"\"\n        t = max(total_rarity, EvolvedParameters.epsilon)\n        m = max(0.0, matched_rarity)\n        return (m / t) ** max(0.0, beta)\n\n    @staticmethod\n    def idf_classic(df: float, N: int) -> float:\n        return math.log((N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene(df: float, N: int) -> float:\n        return math.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_lucene_vectorized(df: NDArray[np.float64], N: int) -> NDArray[np.float64]:\n        return np.log(1.0 + (N - df + 0.5) / (df + 0.5 + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_atire(df: float, N: int) -> float:\n        return math.log(N / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_bm25plus(df: float, N: int) -> float:\n        return math.log((N + 1) / (df + EvolvedParameters.epsilon))\n\n    @staticmethod\n    def idf_smooth(df: float, N: int) -> float:\n        return math.log((N + 0.5) / (df + 0.5))\n\n    @staticmethod\n    def tf_raw(tf: float) -> float:\n        return tf\n\n    @staticmethod\n    def tf_log(tf: float) -> float:\n        return 1.0 + math.log(tf) if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_double_log(tf: float) -> float:\n        if tf <= 0:\n            return 0.0\n        return 1.0 + math.log(1.0 + math.log(tf + 1))\n\n    @staticmethod\n    def tf_boolean(tf: float) -> float:\n        return 1.0 if tf > 0 else 0.0\n\n    @staticmethod\n    def tf_augmented(tf: float, max_tf: float) -> float:\n        return 0.5 + 0.5 * (tf / max_tf) if max_tf > 0 else 0.5\n\n    @staticmethod\n    def saturate(x: float, k: float) -> float:\n        return x / (x + k + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return (tf * (k1 + 1)) / denom\n\n    @staticmethod\n    def saturate_lucene(tf: float, k1: float, norm: float) -> float:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_lucene_vectorized(\n        tf: NDArray[np.float64], k1: float, norm: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n        denom = tf + k1 * norm + EvolvedParameters.epsilon\n        return tf / denom\n\n    @staticmethod\n    def saturate_bm25l(tf: float, k1: float, norm: float, delta: float) -> float:\n        c = tf / (norm + EvolvedParameters.epsilon)\n        c_delta = c + delta\n        return ((k1 + 1) * c_delta) / (k1 + c_delta + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_bm25plus(tf: float, k1: float, norm: float, delta: float) -> float:\n        base = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return base + delta if tf > 0 else base\n\n    @staticmethod\n    def saturate_log(tf: float, k1: float, norm: float) -> float:\n        bm25_sat = (tf * (k1 + 1)) / (tf + k1 * norm + EvolvedParameters.epsilon)\n        return math.log(1.0 + bm25_sat)\n\n    @staticmethod\n    def length_norm_bm25(dl: float, avgdl: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_bm25_vectorized(\n        dl: NDArray[np.float64], avgdl: float, b: float\n    ) -> NDArray[np.float64]:\n        return 1.0 - b + b * (dl / max(avgdl, 1.0))\n\n    @staticmethod\n    def length_norm_pivot(dl: float, pivot: float, b: float) -> float:\n        return 1.0 - b + b * (dl / max(pivot, 1.0))\n\n    @staticmethod\n    def length_norm_log(dl: float, avgdl: float, b: float) -> float:\n        ratio = dl / max(avgdl, 1.0)\n        return 1.0 + b * math.log(ratio) if ratio > 0 else 1.0\n\n    @staticmethod\n    def multiply(*args: float) -> float:\n        result = 1.0\n        for x in args:\n            result *= x\n        return result\n\n    @staticmethod\n    def add(*args: float) -> float:\n        return sum(args)\n\n    @staticmethod\n    def weighted_sum(values: list[float], weights: list[float]) -> float:\n        return sum(v * w for v, w in zip(values, weights, strict=False))\n\n    @staticmethod\n    def geometric_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        product = 1.0\n        for v in values:\n            if v <= 0:\n                return 0.0\n            product *= v\n        return product ** (1.0 / len(values))\n\n    @staticmethod\n    def harmonic_mean(values: list[float]) -> float:\n        if not values:\n            return 0.0\n        reciprocal_sum = sum(1.0 / (v + EvolvedParameters.epsilon) for v in values)\n        return len(values) / reciprocal_sum if reciprocal_sum > 0 else 0.0\n\n    @staticmethod\n    def soft_max(values: list[float], temperature: float = 1.0) -> float:\n        if not values:\n            return 0.0\n        max_val = max(values)\n        exp_sum = sum(math.exp((v - max_val) / temperature) for v in values)\n        return max_val + temperature * math.log(exp_sum)\n\n    @staticmethod\n    def query_weight_uniform(qtf: float, k3: float) -> float:\n        return 1.0\n\n    @staticmethod\n    def query_weight_frequency(qtf: float, k3: float) -> float:\n        return qtf\n\n    @staticmethod\n    def query_weight_saturated(qtf: float, k3: float) -> float:\n        return ((k3 + 1) * qtf) / (k3 + qtf + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def coverage_bonus(matched_terms: int, total_query_terms: int) -> float:\n        if total_query_terms <= 0:\n            return 0.0\n        coverage = matched_terms / total_query_terms\n        return coverage * coverage\n\n    @staticmethod\n    def rarity_boost(idf: float, threshold: float = 3.0) -> float:\n        return 1.0 + (idf - threshold) * 0.1 if idf > threshold else 1.0\n\n\n# ----- EVOLVE: Term score (IDF \u00d7 TF, or your formula) -----\n\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n\n        mix = max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix)))\n        tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n        tf_logsat = ScoringPrimitives.saturate_logtf_lucene(\n            tf, k1, norm, EvolvedParameters.tf_log_k\n        )\n        tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n\n\n# ----- EVOLVE: Doc score (aggregation of term scores) -----\n\nclass DocumentScorer:\n    \"\"\"Aggregate term scores into document score. Evolve aggregation or add new terms.\"\"\"\n\n    @staticmethod\n    def score(\n        term_scores: list[float],\n        query_weights: list[float],\n        matched_count: int,\n        total_query_terms: int,\n        matched_rarity: float = 0.0,\n        total_rarity: float = 0.0,\n    ) -> float:\n        if not term_scores:\n            return 0.0\n        base = ScoringPrimitives.weighted_sum(term_scores, query_weights)\n\n        # Additive coverage bonus keeps recall strong.\n        if EvolvedParameters.gamma > 0:\n            base += EvolvedParameters.gamma * ScoringPrimitives.coverage_bonus(\n                matched_count, total_query_terms\n            )\n\n        # New: rarity-aware coordination multiplier improves early precision (nDCG@10)\n        # while being less harsh than count-based coordination on long/noisy queries.\n        if EvolvedParameters.coord_beta > 0 and total_rarity > 0:\n            base *= ScoringPrimitives.coord_rarity_aware(\n                matched_rarity, total_rarity, EvolvedParameters.coord_beta\n            )\n\n        return base\n\n\n# ----- EVOLVE: Query handling -----\n\nclass QueryProcessor:\n    \"\"\"Turn raw query into (terms, weights). Evolve weighting or dedup strategy.\"\"\"\n\n    @staticmethod\n    def process(query: list[str]) -> tuple[list[str], list[float]]:\n        if not query:\n            return [], []\n        # Deduplicate terms and use saturated qtf weighting (classic BM25 query term factor idea)\n        counts = Counter(query)\n        terms = list(counts.keys())\n        weights = [\n            ScoringPrimitives.query_weight_saturated(float(counts[t]), EvolvedParameters.k3)\n            for t in terms\n        ]\n        return terms, weights\n\n\n# ----- EVOLVE: Full pipeline (or replace with new structure) -----\n\ndef score_kernel(query: list[str], doc_idx: int, corpus: Corpus) -> float:\n    \"\"\"Orchestrate term/doc scoring. Evolve pipeline or replace with a different structure.\"\"\"\n    if not query:\n        return 0.0\n    query_terms, query_weights = QueryProcessor.process(query)\n    if not query_terms:\n        return 0.0\n\n    doc_tf = corpus.get_term_frequencies(doc_idx)\n    dl = corpus.doc_lengths[doc_idx]\n    avgdl = corpus.avgdl\n    N = corpus.N\n\n    term_scores: list[float] = []\n    used_weights: list[float] = []\n    matched_count = 0\n\n    # rarity-mass coverage tracking: use balanced rarity (less spiky than lucene idf)\n    total_rarity = 0.0\n    matched_rarity = 0.0\n    for term in query_terms:\n        df = corpus.get_df(term)\n        total_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    for term, w in zip(query_terms, query_weights, strict=False):\n        tf = doc_tf.get(term, 0)\n        if tf > 0:\n            matched_count += 1\n            df = corpus.get_df(term)\n            term_scores.append(TermScorer.score(tf, df, N, dl, avgdl))\n            used_weights.append(w)\n            matched_rarity += max(0.0, ScoringPrimitives.idf_balanced(float(df), N))\n\n    return DocumentScorer.score(\n        term_scores,\n        used_weights,\n        matched_count,\n        len(query_terms),\n        matched_rarity=matched_rarity,\n        total_rarity=total_rarity,\n    )\n\n\n# ----- Tokenization (fixed; do not evolve) -----\n\n_TOKENIZER: _BaseLuceneTokenizer | None = None\n\ndef _get_tokenizer() -> _BaseLuceneTokenizer:\n    global _TOKENIZER\n    if _TOKENIZER is None:\n        _TOKENIZER = _BaseLuceneTokenizer()\n    return _TOKENIZER\n\ndef tokenize(text: str) -> list[str]:\n    return _get_tokenizer()(text)\n\nclass LuceneTokenizer:\n    def __init__(self):\n        self._tokenizer = _BaseLuceneTokenizer()\n    def __call__(self, text: str) -> list[str]:\n        return self._tokenizer(text)\n\n\n# ----- Corpus (fixed structure; evaluator expects this interface) -----\n\nclass Corpus:\n    \"\"\"Preprocessed collection; inverted index + sparse matrix. Interface must stay stable.\"\"\"\n\n    def __init__(self, documents: list[list[str]], ids: list[str] | None = None):\n        self.documents = documents\n        self.ids = ids or [str(i) for i in range(len(documents))]\n        self._id_to_idx = {doc_id: i for i, doc_id in enumerate(self.ids)}\n        self.N = len(documents)\n        self.document_count = self.N\n        self.doc_lengths = np.array([len(d) for d in documents], dtype=np.float64)\n        self.avgdl = float(np.mean(self.doc_lengths)) if self.N > 0 else 1.0\n        self.average_document_length = self.avgdl\n\n        self._vocab: dict[str, int] = {}\n        term_idx = 0\n        for doc in documents:\n            for term in doc:\n                if term not in self._vocab:\n                    self._vocab[term] = term_idx\n                    term_idx += 1\n        self.vocab_size = len(self._vocab)\n\n        tf_matrix_lil = lil_matrix((self.vocab_size, self.N), dtype=np.float64)\n        self._inverted_index: dict[int, list[int]] = {i: [] for i in range(self.vocab_size)}\n        self._df = np.zeros(self.vocab_size, dtype=np.float64)\n        self._doc_tf_dicts: list[Counter[str]] = [Counter(doc) for doc in documents]\n\n        for doc_idx, doc in enumerate(documents):\n            term_counts = Counter(doc)\n            seen_terms = set()\n            for term, count in term_counts.items():\n                term_id = self._vocab[term]\n                tf_matrix_lil[term_id, doc_idx] = count\n                if term_id not in seen_terms:\n                    self._inverted_index[term_id].append(doc_idx)\n                    self._df[term_id] += 1\n                    seen_terms.add(term_id)\n\n        self.tf_matrix = csr_matrix(tf_matrix_lil)\n        self._posting_lists: dict[int, NDArray[np.int64]] = {\n            term_id: np.array(doc_ids, dtype=np.int64)\n            for term_id, doc_ids in self._inverted_index.items()\n            if doc_ids\n        }\n        del self._inverted_index\n\n        self.idf_array = ScoringPrimitives.idf_lucene_vectorized(self._df, self.N)\n        self.norm_array = ScoringPrimitives.length_norm_bm25_vectorized(\n            self.doc_lengths, self.avgdl, EvolvedParameters.b\n        )\n        self.document_frequency = Counter(\n            {term: int(self._df[term_id]) for term, term_id in self._vocab.items()}\n        )\n        self.document_length = self.doc_lengths\n\n    def __len__(self) -> int:\n        return self.N\n\n    @classmethod\n    def from_huggingface_dataset(cls, dataset) -> Corpus:\n        ids = [doc[\"id\"] for doc in dataset]\n        documents = [tokenize(doc[\"content\"]) for doc in dataset]\n        return cls(documents, ids)\n\n    def get_df(self, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 1\n        return max(1, int(self._df[term_id]))\n\n    def get_tf(self, doc_idx: int, term: str) -> int:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return 0\n        return int(self.tf_matrix[term_id, doc_idx])\n\n    def get_term_frequencies(self, doc_idx: int) -> Counter[str]:\n        return self._doc_tf_dicts[doc_idx]\n\n    def get_posting_list(self, term: str) -> NDArray[np.int64]:\n        term_id = self._vocab.get(term)\n        if term_id is None:\n            return np.array([], dtype=np.int64)\n        return self._posting_lists.get(term_id, np.array([], dtype=np.int64))\n\n    def get_term_id(self, term: str) -> int | None:\n        return self._vocab.get(term)\n\n    def id_to_idx(self, ids: list[str]) -> list[int]:\n        return [self._id_to_idx[doc_id] for doc_id in ids if doc_id in self._id_to_idx]\n\n    @property\n    def map_id_to_idx(self) -> dict[str, int]:\n        return self._id_to_idx\n\n    @property\n    def vocabulary_size(self) -> int:\n        return self.vocab_size\n\n    @property\n    def term_doc_matrix(self) -> None:\n        return None\n\n    @property\n    def term_frequency(self) -> list[Counter[str]]:\n        return self._doc_tf_dicts\n\n\n# ----- BM25 API (interface fixed for evaluator) -----\n\nclass BM25:\n    \"\"\"Scorer: uses score_kernel for single-doc; vectorized path for batch (same formula).\"\"\"\n\n    def __init__(self, corpus: Corpus):\n        self.corpus = corpus\n\n    def score(self, query: list[str], index: int) -> float:\n        return score_kernel(query, index, self.corpus)\n\n    def _score_candidates_vectorized(\n        self,\n        query_term_ids: list[int],\n        candidate_docs: NDArray[np.int64],\n        query_term_weights: NDArray[np.float64] | None = None,\n    ) -> NDArray[np.float64]:\n        if len(candidate_docs) == 0:\n            return np.array([], dtype=np.float64)\n\n        norms = self.corpus.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n        for i, term_id in enumerate(query_term_ids):\n            idf = self.corpus.idf_array[term_id]\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            matched += (tf_row > 0).astype(np.float64)\n\n            tf_sat = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            tf_logsat = ScoringPrimitives.saturate_logtf_lucene_vectorized(\n                tf_row, k1, norms, EvolvedParameters.tf_log_k\n            )\n            tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n            scores += weight * idf * rescue * tf_comp\n\n        qn = float(len(query_term_ids))\n        if EvolvedParameters.gamma > 0 and qn > 0:\n            coverage = matched / qn\n            scores += EvolvedParameters.gamma * (coverage * coverage)\n\n        # Rarity-aware coordination (match score_kernel/DocumentScorer structure).\n        if EvolvedParameters.coord_beta > 0 and qn > 0:\n            # balanced rarity per query term (bounded)\n            df_q = self.corpus._df[np.array(query_term_ids, dtype=np.int64)]\n            rarity_q = ScoringPrimitives.idf_balanced_vectorized(df_q, self.corpus.N)\n            rarity_q = np.maximum(rarity_q, 0.0)\n            total_rarity = float(np.sum(rarity_q))\n            if total_rarity > 0:\n                # matched_rarity: sum rarity of query terms present in doc\n                matched_rarity = np.zeros(len(candidate_docs), dtype=np.float64)\n                for i, term_id in enumerate(query_term_ids):\n                    tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n                    matched_rarity += (tf_row > 0).astype(np.float64) * float(rarity_q[i])\n\n                scores *= np.power(\n                    np.maximum(matched_rarity / total_rarity, 0.0),\n                    EvolvedParameters.coord_beta,\n                )\n\n        return scores\n\n    def rank(\n        self,\n        query: list[str],\n        top_k: int | None = None,\n    ) -> tuple[np.ndarray, np.ndarray]:\n        if not query:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        # Keep rank() consistent with QueryProcessor: dedup + saturated qtf\n        term_counts = Counter(query)\n        query_term_ids: list[int] = []\n        query_term_weights: list[float] = []\n        for term, count in term_counts.items():\n            term_id = self.corpus.get_term_id(term)\n            if term_id is not None:\n                query_term_ids.append(term_id)\n                query_term_weights.append(\n                    ScoringPrimitives.query_weight_saturated(float(count), EvolvedParameters.k3)\n                )\n\n        if not query_term_ids:\n            indices = np.arange(self.corpus.N, dtype=np.int64)\n            scores = np.zeros(self.corpus.N, dtype=np.float64)\n            return indices, scores\n\n        qtf_weights = np.array(query_term_weights, dtype=np.float64)\n\n        candidate_set: set[int] = set()\n        for term_id in query_term_ids:\n            posting_list = self.corpus._posting_lists.get(term_id, np.array([], dtype=np.int64))\n            candidate_set.update(posting_list.tolist())\n\n        candidate_docs = np.array(sorted(candidate_set), dtype=np.int64)\n        candidate_scores = self._score_candidates_vectorized(\n            query_term_ids, candidate_docs, qtf_weights\n        )\n\n        all_scores = np.zeros(self.corpus.N, dtype=np.float64)\n        all_scores[candidate_docs] = candidate_scores\n        sorted_indices = np.argsort(-all_scores).astype(np.int64)\n        sorted_scores = all_scores[sorted_indices]\n        if top_k is not None:\n            sorted_indices = sorted_indices[:top_k]\n            sorted_scores = sorted_scores[:top_k]\n        return sorted_indices, sorted_scores\n\n    def batch_rank(\n        self,\n        queries: list[list[str]],\n        top_k: int | None = None,\n    ) -> list[tuple[np.ndarray, np.ndarray]]:\n        if len(queries) < MIN_QUERIES_FOR_PARALLEL:\n            return [self.rank(query, top_k) for query in queries]\n        with ThreadPoolExecutor(max_workers=NUM_QUERY_WORKERS) as executor:\n            return list(executor.map(lambda q: self.rank(q, top_k), queries))\n\n\n__all__ = [\n    \"BM25\",\n    \"Corpus\",\n    \"tokenize\",\n    \"LuceneTokenizer\",\n    \"LUCENE_STOPWORDS\",\n    \"ENGLISH_STOPWORDS\",\n    \"EvolvedParameters\",\n    \"ScoringPrimitives\",\n    \"TermScorer\",\n    \"DocumentScorer\",\n    \"QueryProcessor\",\n    \"score_kernel\",\n]\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Below are targeted changes aimed at recovering the fitness drop and improving **combined_score**. The main issue with the current program is that the new **log-TF compression** likely hurts *Recall@100* on \u201cneedle-in-haystack\u201d datasets (SciFact/TREC-COVID style) by under-rewarding repeated evidence in longer docs, while not providing a strong enough upside elsewhere. I propose:\n\n1) **Make TF compression rarity-adaptive**: compress only for common terms (bursty noise), but keep near-standard BM25/Lucene saturation for rare terms (important for recall).  \n2) **Re-introduce the previously strong TF blend (tf_salience)** that helped long/noisy docs without killing recall.  \n3) Keep changes minimal and local (no new expensive doc scanning).\n\n---\n\n### Change 1 \u2014 Add rarity-adaptive TF mixing parameters\nThis makes the log-TF compression only kick in when a term is *not very rare*, preserving rare-term strength for recall.\n\n<<<<<<< SEARCH\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n    alpha: float = 1.0\n    beta: float = 1.0\n\n    # Light document-level priors\n    gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    # New: burstiness-aware TF compression (helps noisy/repetitive docs; preserves 1-hit signal)\n    tf_log_mix: float = 0.35  # 0 => pure lucene saturation, 1 => pure log-TF saturation\n    tf_log_k: float = 1.0     # higher => weaker log compression\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n=======\nclass EvolvedParameters:\n    \"\"\"Numeric parameters. Evolve values or add new ones. Defaults match Pyserini.\"\"\"\n    k1: float = 0.9\n    b: float = 0.4\n    k3: float = 8.0\n    delta: float = 0.5\n    alpha: float = 1.0\n    beta: float = 1.0\n\n    # Light document-level priors\n    gamma: float = 0.22  # slightly lower; will be combined with a *rarity-aware* coordination below\n\n    # Frequent-term recall rescue (bounded)\n    common_strength: float = 0.25\n    common_pivot: float = 2.5\n\n    # New: rarity-aware coordination (soft AND weighted by query-term rarity)\n    coord_beta: float = 0.55\n\n    # Burstiness-aware TF compression, but now made *rarity-adaptive* (protects recall for rare terms)\n    tf_log_mix: float = 0.35  # base strength (still used, but gated by rarity)\n    tf_log_k: float = 1.0     # higher => weaker log compression\n    tf_mix_idf_pivot: float = 2.2   # lucene-idf pivot: above this => little/no log compression\n    tf_mix_idf_sharp: float = 1.0   # larger => sharper transition around pivot\n\n    # Restore helpful TF blend for long/noisy docs\n    tf_salience_alpha: float = 0.35  # 0 => ignore salience; 1 => only salience\n\n    epsilon: float = 1e-9\n    max_idf: float = float(\"inf\")\n    min_idf: float = 0.0\n>>>>>>> REPLACE\n\n---\n\n### Change 2 \u2014 Add a TF salience primitive (and vectorized version)\nThis was a key contributor in the top program: it downweights inflated TF in long documents without crushing single hits.\n\n<<<<<<< SEARCH\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def saturate_logtf_lucene(tf: float, k1: float, norm: float, k: float) -> float:\n=======\nclass ScoringPrimitives:\n    \"\"\"IDF, TF, saturation, length norm, aggregation. Invent new primitives or new formulas.\"\"\"\n\n    @staticmethod\n    def tf_salience(tf: float, dl: float, avgdl: float) -> float:\n        \"\"\"\n        Length-aware TF salience: downweights inflated TF in long docs.\n        Works as a smooth alternative evidence channel to protect recall.\n        \"\"\"\n        denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n        return tf / (denom + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def tf_salience_vectorized(\n        tf: NDArray[np.float64], dl: NDArray[np.float64], avgdl: float\n    ) -> NDArray[np.float64]:\n        denom = tf + 0.5 * (dl / max(avgdl, 1.0)) + 1.0\n        return tf / (denom + EvolvedParameters.epsilon)\n\n    @staticmethod\n    def saturate_logtf_lucene(tf: float, k1: float, norm: float, k: float) -> float:\n>>>>>>> REPLACE\n\n---\n\n### Change 3 \u2014 Make TermScorer rarity-adaptive and blend with tf_salience\nWe compute a **per-term mix**:\n- If term is rare (high idf): use mostly standard Lucene saturation (good for recall).\n- If term is common (low idf): allow more log-TF compression (good for noisy corpora).\nThen blend with tf_salience to keep robustness for long docs.\n\n<<<<<<< SEARCH\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n\n        mix = max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix)))\n        tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n        tf_logsat = ScoringPrimitives.saturate_logtf_lucene(\n            tf, k1, norm, EvolvedParameters.tf_log_k\n        )\n        tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n=======\nclass TermScorer:\n    \"\"\"One term's contribution. Evolve the formula; invent new combinations or new math.\"\"\"\n\n    @staticmethod\n    def score(tf: float, df: float, N: int, dl: float, avgdl: float) -> float:\n        if tf <= 0:\n            return 0.0\n        k1, b = EvolvedParameters.k1, EvolvedParameters.b\n        idf = ScoringPrimitives.idf_lucene(df, N)\n        idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n        norm = ScoringPrimitives.length_norm_bm25(dl, avgdl, b)\n\n        # Rarity-adaptive burstiness handling:\n        # - rare terms (high idf): keep mostly standard saturation (protect recall)\n        # - common terms (low idf): allow more log-TF compression (reduce noisy bursts)\n        base_mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n        pivot = float(EvolvedParameters.tf_mix_idf_pivot)\n        sharp = float(max(EvolvedParameters.epsilon, EvolvedParameters.tf_mix_idf_sharp))\n        gate = 1.0 / (1.0 + math.exp((idf - pivot) / sharp))  # high for common terms\n        mix = base_mix * gate\n\n        tf_sat = ScoringPrimitives.saturate_lucene(tf, k1, norm)\n        tf_logsat = ScoringPrimitives.saturate_logtf_lucene(tf, k1, norm, EvolvedParameters.tf_log_k)\n        tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n\n        # Add a second evidence channel that is robust for long docs.\n        a = float(max(0.0, min(1.0, float(EvolvedParameters.tf_salience_alpha))))\n        tf_sal = ScoringPrimitives.tf_salience(tf, dl, avgdl)\n        tf_comp = (1.0 - a) * tf_comp + a * tf_sal\n\n        rescue = ScoringPrimitives.commonness_rescue(\n            idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n        )\n        return idf * tf_comp * rescue\n>>>>>>> REPLACE\n\n---\n\n### Change 4 \u2014 Update vectorized scoring to match TermScorer (consistency)\nThis is important: the evaluator mostly uses the vectorized path; if it diverges from score_kernel/TermScorer behavior, you get unstable behavior.\n\n<<<<<<< SEARCH\n        norms = self.corpus.norm_array[candidate_docs]\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n        for i, term_id in enumerate(query_term_ids):\n            idf = self.corpus.idf_array[term_id]\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                float(idf), EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            matched += (tf_row > 0).astype(np.float64)\n\n            tf_sat = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            tf_logsat = ScoringPrimitives.saturate_logtf_lucene_vectorized(\n                tf_row, k1, norms, EvolvedParameters.tf_log_k\n            )\n            tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n            scores += weight * idf * rescue * tf_comp\n=======\n        norms = self.corpus.norm_array[candidate_docs]\n        dls = self.corpus.doc_lengths[candidate_docs]\n        avgdl = self.corpus.avgdl\n\n        scores = np.zeros(len(candidate_docs), dtype=np.float64)\n        matched = np.zeros(len(candidate_docs), dtype=np.float64)\n\n        k1 = EvolvedParameters.k1\n        base_mix = float(max(0.0, min(1.0, float(EvolvedParameters.tf_log_mix))))\n        pivot = float(EvolvedParameters.tf_mix_idf_pivot)\n        sharp = float(max(EvolvedParameters.epsilon, EvolvedParameters.tf_mix_idf_sharp))\n        sal_a = float(max(0.0, min(1.0, float(EvolvedParameters.tf_salience_alpha))))\n\n        for i, term_id in enumerate(query_term_ids):\n            idf = float(self.corpus.idf_array[term_id])\n            if idf <= 0:\n                continue\n            idf = max(EvolvedParameters.min_idf, min(idf, EvolvedParameters.max_idf))\n\n            rescue = ScoringPrimitives.commonness_rescue(\n                idf, EvolvedParameters.common_strength, EvolvedParameters.common_pivot\n            )\n\n            weight = query_term_weights[i] if query_term_weights is not None else 1.0\n            tf_row = self.corpus.tf_matrix[term_id, candidate_docs].toarray().ravel()\n            present = (tf_row > 0).astype(np.float64)\n            matched += present\n\n            # Rarity-adaptive mix (same logic as TermScorer, vectorized)\n            gate = 1.0 / (1.0 + math.exp((idf - pivot) / sharp))\n            mix = base_mix * gate\n\n            tf_sat = ScoringPrimitives.saturate_lucene_vectorized(tf_row, k1, norms)\n            tf_logsat = ScoringPrimitives.saturate_logtf_lucene_vectorized(\n                tf_row, k1, norms, EvolvedParameters.tf_log_k\n            )\n            tf_comp = (1.0 - mix) * tf_sat + mix * tf_logsat\n\n            if sal_a > 0:\n                tf_sal = ScoringPrimitives.tf_salience_vectorized(tf_row, dls, avgdl)\n                tf_comp = (1.0 - sal_a) * tf_comp + sal_a * tf_sal\n\n            scores += weight * idf * rescue * tf_comp\n>>>>>>> REPLACE\n\n---\n\n## Why this should improve fitness\n\n- **Recall@100 protection**: rare terms are no longer log-compressed (or only slightly), restoring the strong \u201cfind the right doc\u201d behavior in scientific/biomed and QA corpora.\n- **nDCG@10 stability**: common/bursty terms are still controlled via log-TF compression, which helps StackOverflow-like and verbose docs.\n- **Long-doc robustness**: reintroducing `tf_salience` tends to help heterogeneous corpora where length normalization alone is insufficient.\n- **Runtime**: only adds a few scalar ops per term; no new per-doc scanning; vectorized path remains fast.\n\nIf you want an even smaller change-set (to satisfy \u201csimplifying\u201d), the minimum subset is **Change 1 + Change 3 + Change 4** (rarity-adaptive mixing), but I expect adding `tf_salience` provides extra robustness across BEIR/BRIGHT."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}