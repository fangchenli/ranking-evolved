# OpenEvolve configuration for BM25 ranking evolution on BRIGHT
#
# Evolution targets in src/ranking_evolved/bm25_evolved.py (~200 lines):
# - EvolvedIDF.compute() - IDF formula
# - EvolvedTF.compute() - TF saturation formula
# - BM25.score_kernel() - Main scoring function
#
# Run with:
#   export OPENAI_API_KEY="your-key"
#   uv run openevolve-run src/ranking_evolved/bm25_evolved.py evaluator_bright.py --config openevolve_config.yaml
#
# Configure evaluation via env vars:
#   BRIGHT_DOMAIN=aops (or biology, theoremqa_theorems, all)
#   BRIGHT_SAMPLE_QUERIES=20 (for faster iteration)
#   BRIGHT_TOKENIZER=simple (or lucene)

max_iterations: 200
log_level: "INFO"
random_seed: 42
diff_based_evolution: true
max_code_length: 12000  # bm25_evolved.py is ~270 lines with vectorized rank

llm:
  models:
    - name: "gpt-4o"
      weight: 1.0
  api_base: "https://api.openai.com/v1"
  api_key: null  # falls back to OPENAI_API_KEY env var
  temperature: 0.7
  top_p: 0.95
  max_tokens: 8192
  timeout: 180
  retries: 3
  retry_delay: 5

prompt:
  system_message: |
    You are evolving a BM25 ranking function for the BRIGHT benchmark.

    ## Evolution Targets (in bm25_evolved.py)
    1. `EvolvedIDF.compute()` - IDF formula
    2. `EvolvedTF.compute()` - TF saturation
    3. `BM25.score_kernel()` - Scoring function

    ## Current Formulas
    - IDF: clip(log((N+0.5)/(df+0.5)), 0, 8)
    - TF: log(1 + tf_raw * tf_sat) where tf_sat = tf/(tf+k1+0.5)
    - Parameters: k1=0.9, b=0.4

    ## Guidelines
    - Keep changes minimal and targeted
    - Preserve BM25 interface (Corpus, rank signatures)
    - No new dependencies - only numpy is available
    - Ensure numerical stability (avoid division by zero)
    - Infrastructure (tokenizers, Corpus) is imported - don't modify

    ## Areas to Explore
    - Different IDF smoothing/scaling
    - Alternative TF saturation curves
    - Non-linear score combinations

  evaluator_system_message: |
    You review candidate BM25 ranking code for correctness and quality.
    Check for: numerical stability, interface compatibility, and meaningful ranking behavior.

  num_top_programs: 3
  num_diverse_programs: 2
  use_template_stochasticity: true
  include_artifacts: true

database:
  in_memory: true
  population_size: 200
  archive_size: 50
  num_islands: 3
  migration_interval: 20
  migration_rate: 0.1
  feature_dimensions:
    - "complexity"
    - "diversity"
  feature_bins: 10
  log_prompts: true

evaluator:
  timeout: 900  # 15 minutes per evaluation (aops has 188k docs)
  max_retries: 2
  cascade_evaluation: false
  parallel_evaluations: 1  # Sequential to avoid memory issues with large corpora

evolution_trace:
  enabled: true
  format: "jsonl"
  include_code: true
  include_prompts: false
